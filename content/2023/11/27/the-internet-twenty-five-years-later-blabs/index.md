---
title: The Internet Twenty-Five Years Later 二十五年后的互联网
date: 2023-11-27T08:27:50.000Z
updated: 2023-11-27T08:27:50.000Z
published: 2023-04-21T08:27:50.000Z
taxonomies:
  tags:
    - Tech
extra:
  source: >-
    https://labs.apnic.net/index.php/2023/04/21/the-internet-twenty-five-years-later/?utm_source=pocket_saves
  hostname: labs.apnic.net
  author: Geoff Huston
  original_title: The Internet Twenty-Five Years Later
  comment: >-
    躺在待阅清单许久，直到前段时间读到教育网络的翻译，才又翻出来这个原版。作者纵横捭阖，总论互联网50年，尤其是后25年，并稍稍展望未来25年，依次呼应杂志约稿，值得一读。
  original_lang: en

---

This article resulted from a request by [The Internet Protocol Journal](http://protocoljournal.org/) (IPJ), which will celebrate its 25th anniversary in June 2023. Another version of this article will appear in the June edition of IPJ.  

本文应《互联网协议杂志》(IPJ) 的要求而撰写，该杂志将于 2023 年 6 月庆祝创刊 25 周年。本文的另一个版本将出现在 IPJ 的 6 月版中。

The Internet not quite as young and spritely as you might’ve thought. Apple’s iPhone, released in 2007, is now 16 years old, and YouTube is an ageing teenager at 18, after its initial release in 2005, and these two examples are relatively recent additions to the Internet. The first web browser, Mosaic, was released some thirty years ago in 1993. Going back further, the Internet emerged from its early ARPA roots in the form of the NSFNET in 1986. At the start of 1983 the ARPANET had a flag day and switched over to use TCP aas its end-to-end transport protocol. Going back further, in 1974 Vint Cerf and Bob Kahn published the first academic paper describing the both the protocol and the underlying architectural framework of a packet switched network that became the Internet. This achievement was built upon earlier foundations, where there were a number of efforts in the late 1960’s that showed the viability of a packet switched approach to computer networking. These packet-switched networking efforts included a program lead by Donald Davies at the UK National Physics Laboratory, an effort in the US in the form of an ARPA project lead by Larry Roberts, and Louis Pouzin’s work in France with the CYCLADES network. This, in turn has some of its antecedents in work by Paul Baran at the RAND Corporation on distributed communications and packet switched networks, published between 1960 and 1964. Far from being an immature upstart, the Internet has managed to accumulate a relatively lengthy pedigree.  

互联网并不像你想象的那么年轻和充满活力。苹果公司的 iPhone 于 2007 年发布，现在已经 16 岁了，而 YouTube 在 2005 年首次发布后，已经是 18 岁的少年了，这两个例子都是互联网上相对较新的产品。第一个 Web 浏览器 Mosaic 于大约 30 年前的 1993 年发布。回溯到更远的历史时期，互联网于 1986 年以 NSFNET 的形式从早期的 ARPA 根源中诞生。1983 年初，ARPANET 迎来了一个旗帜日，并进行了切换。转而使用 TCP 作为其端到端传输协议。更进一步来说，1974 年 Vint Cerf 和 Bob Kahn 发表了第一篇学术论文，描述了后来成为互联网的分组交换网络的协议和底层架构框架。这一成就建立在早期的基础上，1960 年代末的许多努力表明了计算机网络的数据包交换方法的可行性。这些数据包交换网络工作包括英国国家物理实验室的 Donald Davies 领导的项目、Larry Roberts 领导的美国 ARPA 项目以及 Louis Pouzin 在法国的 CYCLADES 网络工作。这反过来又与兰德公司的保罗·巴兰 (Paul Baran) 在 1960 年至 1964 年间发表的关于分布式通信和分组交换网络的工作有关。互联网远非一个不成熟的新贵，它已经成功地积累了相对较长的谱系。

And it’s been a wild ride. The Internet has undergone a number of cycles of economic boom and bust, each of which are right up there with history’s finest episodes of exuberant irrational mania following by sobering correction. It’s managed to trigger a comprehensive restructuring of the entire global communications enterprise and generated a set of changes that have already altered the way in which each of us now work and play. That’s quite a set of achievements in just twenty-five years!  

这是一次疯狂的旅程。互联网经历了多次经济繁荣和萧条的周期，每一次都伴随着历史上最精彩的非理性狂热，随后是令人清醒的纠正。它成功引发了整个全球通信企业的全面重组，并产生了一系列变化，这些变化已经改变了我们每个人现在的工作和娱乐方式。短短二十五年内取得的成就相当可观！

We start this exploration of the Internet’s last quarter century in 1998. At that time any lingering doubts about the ultimate success of the Internet as a global communications medium had been thoroughly dispelled. The Internet was no longer just a research experiment, or an intermediate way stop on the road to adoption of the Open Systems Interconnect (OSI) framework. By 1998 there was nothing else left standing in the data communications landscape that could serve our emerging needs for data communications. IP was now the communications technology for the day, if not for the coming century, and the industry message at the time was a clear one that directed communications enterprises to adopt the Internet into every product and service or imperil their entire future in this business. No longer could the traditional telecommunications enterprises view the Internet with some polite amusement or even overt derision. It was now time for a desperate scramble to be part of this revolution in one of the world’s major activity sectors. The largest enterprises in this sector, the old-world ex-monopoly telcos, had been caught wrong-footed in one of the biggest changes of the industry for many decades, and this time the concurrent wave of deregulation and competition meant that the communications industry’s entire future was being handed over to a small clique of Internet players.  

我们从 1998 年开始对互联网最后四分之一个世纪的探索。那时，对互联网作为全球通信媒介最终能否成功的任何挥之不去的疑虑都已彻底消除。互联网不再只是一个研究实验，或者是采用开放系统互连 (OSI) 框架道路上的中间站。到 1998 年，数据通信领域已经没有其他任何东西可以满足我们新兴的数据通信需求。 IP 现在是当今的通信技术，即使不是下个世纪的通信技术，当时的行业信息很明确，指示通信企业将互联网应用于每一种产品和服务，否则将危及他们在该行业的整个未来。传统电信企业不再以礼貌的娱乐甚至公然的嘲笑来看待互联网。现在是时候拼命争夺世界主要活动领域之一的这场革命的一部分了。该行业最大的企业，即旧世界的前垄断电信公司，在数十年来该行业最大的变革之一中措手不及，而这一次同时出现的放松管制和竞争浪潮意味着通信行业的整个未来都被交给了一小群互联网玩家。

By 1998 the Internet had finally made it into the big time. The job was apparently done, and the Internet had prevailed. But soon after came a new revolution, this time in mobility services, where after a number of very clunky initial efforts by others (does anyone remember “WAP”?), the iPhone entered the market with a seamless blend of sleek design and astounding capability. The mobile carriage sector struggled to keep up with the new levels of rapacious demand for Internet-based mobile data. Riding on the back of this success, the Internet then took on the television networks, competing with the incumbent broadcast and cable systems with streaming video. The story is not over by any means. Communications continues to drive our world, and the Internet continues to evolve and change.  

到 1998 年，互联网终于盛行起来。任务显然已经完成，互联网已经盛行。但不久之后，一场新的革命发生了，这次是在移动服务领域，在其他人进行了一系列非常笨拙的初步努力之后（还有人记得“WAP”吗？），iPhone 凭借时尚设计和令人惊叹的功能的无缝融合进入了市场。移动运输行业努力跟上对基于互联网的移动数据的新的贪婪需求。凭借这一成功，互联网随后与电视网络展开竞争，通过流媒体视频与现有的广播和有线电视系统竞争。无论如何，故事还没有结束。通信继续推动我们的世界发展，互联网也在不断发展和变化。

The evolutionary path of any technology can often take strange and unanticipated turns and twists. At some points simplicity and minimalism can be replaced by complexity and ornamentation, while at other times a dramatic cut-through exposes the core concepts of the technology and removes layers of superfluous additions. The technical evolution of the Internet appears to be no exception and this story contains these same forms of unanticipated turns and twists.  

任何技术的进化之路常常会出现奇怪的、意想不到的转折和曲折。在某些时候，简单和极简主义可以被复杂性和装饰所取代，而在其他时候，戏剧性的突破暴露了技术的核心概念，并消除了多余的附加内容。互联网的技术演变似乎也不例外，这个故事也包含同样形式的意想不到的转折和曲折。

Rather than offer a set of unordered observations about the various changes and developments over the past twenty-five years, I’ll use the traditional protocol stack model as a template, starting with the underlying transmission media, then looking at IP, the transport layer, then applications and services, and closing with a look at the business of the Internet.  

我不会对过去二十五年来的各种变化和发展提供一系列无序的观察，而是使用传统的协议栈模型作为模板，从底层传输介质开始，然后查看 IP（传输层） ，然后是应用程序和服务，最后回顾一下互联网业务。

### Transmission 传播

It seems like a totally alien concept these days, but the Internet Service Provider business of 1998 was still based around the technology of dial-up modems. The state of the art of modem speed had been continually refined, from 9600bps to 14.4kbps, to 28kbps to, finally, 56kbps, squeezing every last bit out the phase amplitude encoding space contained in an analogue voice circuit. Analogue modems were capricious, constantly being superseded by the next technical refinement, unreliable, difficult for customers to use, and on top of that they were just slow! Almost everything else on the Internet was forced to be tailored to download reasonably quickly over a modem connection. Web pages were carefully composed with compressed images to ensure a rapid download, and plain text was the dominant medium as a consequence. It could only get better, and it did.  

如今，这似乎是一个完全陌生的概念，但 1998 年的互联网服务提供商业务仍然基于拨号调制解调器技术。最先进的调制解调器速度不断得到改进，从 9600bps 到 14.4kbps，再到 28kbps，最后到 56kbps，将模拟语音电路中包含的相位幅度编码空间的每一位都挤出来。模拟调制解调器反复无常，不断被新的技术改进所取代，不可靠，客户难以使用，而且最重要的是速度很慢！互联网上的几乎所有其他内容都被迫进行定制，以便通过调制解调器连接以相当快的速度下载。网页是用压缩图像精心组成的，以确保快速下载，因此纯文本成为主要媒体。它只会变得更好，而且确实如此。

The evolution of access networks was initially one that exposed the inner digital core of the network out to the edges. The first approach was ISDN, where the underlying digitised voice circuit was drawn out to the network’s edge. At 64bps this was just an inadequate level of improvement over these analogue modems, and the next major step in access technology was to use DSL. DSL still used the last mile of the network into an analogue channel, but instead of running single low speed analogue bearer signal, DSL layered a large collection of individual analogue bearer signals into the access circuit, performing a form of frequency division multiplexing on the basic analogue circuit in a trellis framework. DSL relied on the combination of the telephone company’s efforts to operate the copper access circuits within a high-level level of signal quality and noise suppression parameters, and the modem industry’s continual incremental improvements in digital signal processing capability. Surprisingly, DSL was often able to achieve speeds of tens of megabits per second through these legacy copper access networks. However, DSL was largely an interim holding position while the search for a viable business model that was capable of underwriting the costs of deployment and use of an open fibre-based access networks was underway that was going to replace the aging copper access network.  

接入网络的发展最初是将网络的内部数字核心暴露到边缘。第一种方法是 ISDN，其中底层数字化语音电路被引至网络边缘。在 64bps 下，与这些模拟调制解调器相比，这还远远不够，接入技术的下一个主要步骤是使用 DSL。 DSL 仍然使用网络的最后一英里进入模拟通道，但 DSL 不是运行单个低速模拟承载信号，而是将大量单独的模拟承载信号分层到接入电路中，在基本网络上执行频分复用的形式。网格框架中的模拟电路。 DSL 依赖于电话公司在高水平的信号质量和噪声抑制参数范围内操作铜接入电路的努力以及调制解调器行业在数字信号处理能力方面的不断增量改进的结合。令人惊讶的是，DSL 通常能够通过这些传统铜线接入网络实现每秒数十兆比特的速度。然而，DSL 在很大程度上只是一种临时持有立场，同时正在寻找一种可行的商业模式，该模式能够承担部署和使用基于开放光纤的接入网络的成本，以取代老化的铜线接入网络。

The transition into fixed-wire access networks based on fibre optic cable continues. As noted already, the challenge in fibre access networking lies in finding a suitable business model than can sustain the necessary capital investment in replacing the existing copper-based network infrastructure. Some national communities used a model of a public sector program, such as the National Broadband Network program in Australia, while others have remained as dedicated private sector activities, and others take a hybrid approach with some level of local public sector incentives being added into a private sector program. The issue here is that fixed wire residential access networks do not offer compelling investment opportunities in most cases, with the high upfront capital costs and the generally inadequate levels of take up across the dwellings passed by the access infrastructure acting as disinhibitory factors. It is often the case that a residential community cannot support multiple fibre access network deployments, bringing up the related issue of local access monopolies and the challenge of permitting some level of competitive access across a single physical access network. Nevertheless, fibre access rollouts continue across many parts of the world and the transition of the wired copper network into a fibre access network capable of sustaining hundreds of megabits per connection is still progressing, seemingly in spite of the barriers that exist in many scenarios.  

向基于光缆的固定线路接入网络的过渡仍在继续。如前所述，光纤接入网络的挑战在于找到一种合适的商业模式，能够维持替换现有铜基网络基础设施所需的资本投资。一些国家社区采用了公共部门计划的模式，例如澳大利亚的国家宽带网络计划，而另一些国家社区则仍然作为专门的私营部门活动，而另一些国家则采取混合方法，将一定程度的地方公共部门激励措施添加到项目中。私营部门计划。这里的问题是，在大多数情况下，固定有线住宅接入网络并不能提供令人信服的投资机会，高昂的前期资本成本以及接入基础设施所经过的住宅的占用水平普遍不足，成为抑制因素。通常情况下，住宅社区无法支持多个光纤接入网络部署，从而引发本地接入垄断的相关问题以及允许跨单个物理接入网络进行某种程度的竞争性接入的挑战。尽管如此，光纤接入在世界许多地区仍在继续推广，尽管在许多情况下都存在障碍，但从有线铜质网络到能够维持每个连接数百兆比特的光纤接入网络的过渡仍在进行中。

The mobile access network has experienced a completely different evolution, and for many years now the mobile sector has been demand-driven. The first mobile data service networks, introduced in the 1980’s, were little more than low-speed digital encoders working across a single voiceband circuit. These 1G networks typically delivered a 2.4Kbps data download capacity. The next generation of mobile services, 2G, was used in the 1990’s. It was still predominately a voice service, and while it could theoretically support data access at speeds of 100kbps, this data transfer rate was largely aspirational. The intersection of the Internet and mobile services occurred with the introduction of 3G mobile services. The 3G architecture was capable of pushing IP connectivity directly out to the handset, supporting data transfer speeds of 1–2Mbps. This network capability, coupled with a new generation of handsets, first with the BlackBerry in 2002, and then the iPhone in 2007, transformed the mobile service into a mass market consumer service. The high margins available from the service captured the attention of the traditional voice industry and the result was a large scale opening up of radio spectrum to create an Internet access environment that quickly rivalled the wire-line access market in size, but totally outpaced it in terms of revenue margins. This massive escalation of demand created further pressures on the capacity of the mobile system, and in 2009 the mobile sector introduced 4G services, opening up more spectrum bands, and also adding Multiple-Input Multiple Output (MIMO) radio technologies to the mobile device to achieve greater deliverable capacity to each connected device. Over time these services were configured to deliver peak download speeds of 50Mbps to 100Mbps per device. The industry was also selling hundreds of millions of mobile devices per year. 4G dispensed with circuit-switched services, and it exclusively used packet switching. In 2018 5G was introduced. 5G can be supported more spectrum bands, including a high-band millimetre spectrum at 24-47Ghz. These higher carrier frequencies permit multi-gigabit data services, but they come at a cost of higher density of base station towers to compensate for the lower signal propagation distances associated with higher radio frequencies.  

移动接入网络经历了完全不同的演变，多年来移动行业一直是需求驱动的。第一个移动数据服务网络于 20 世纪 80 年代推出，只不过是在单个语音频带电路上工作的低速数字编码器。这些 1G 网络通常提供 2.4Kbps 的数据下载能力。下一代移动服务 2G 于 20 世纪 90 年代使用。它仍然主要是语音服务，虽然理论上它可以支持 100kbps 的数据访问速度，但这种数据传输速率在很大程度上是理想的。随着 3G 移动服务的推出，互联网和移动服务发生了交叉。 3G 架构能够将 IP 连接直接推送至手机，支持 1-2Mbps 的数据传输速度。这种网络功能，加上新一代手机（首先是 2002 年的黑莓手机，然后是 2007 年的 iPhone），将移动服务转变为大众市场消费服务。该服务的高利润引起了传统语音行业的关注，其结果是大规模开放无线电频谱，创建了一个互联网接入环境，在规模上迅速与有线接入市场相媲美，但在业务方面却完全超过了有线接入市场。收入利润率方面。需求的大规模升级对移动系统的容量造成了进一步的压力，2009年移动部门推出了4G服务，开放了更多频段，并在移动设备中添加了多输入多输出（MIMO）无线电技术，以提高移动设备的性能。为每个连接的设备实现更大的交付能力。 随着时间的推移，这些服务被配置为每台设备提供 50Mbps 至 100Mbps 的峰值下载速度。该行业每年还销售数亿台移动设备。 4G 放弃了电路交换服务，而专门使用分组交换。 2018年推出5G。 5G可支持更多频段，包括24-47Ghz的高频段毫米波频谱。这些更高的载波频率允许多千兆位数据服务，但它们的代价是基站塔密度更高，以补偿与更高无线电频率相关的更短的信号传播距离。

There was a second radio technology that emerged in 1998 that has also transformed the Internet, and it could be argued that it has become so fundamental that it has weaved itself so naturally into our environment that it all but disappeared (to adapt a quotation from Mark Weiser, [The Computer for the 21st Century](https://web.archive.org/web/20141022035044/http://www.ubiq.com/hypertext/weiser/SciAmDraft3.html), 1997). The combination of low power radio systems and unlicensed radio spectrum allocation, or WiFi, and subsequently Bluetooth, has been transformational. The combination of efficient battery technology, computer chips that operate with low power consumption, and the unwiring of the last few meters in the home and office completely changed our collective of technology, and it is only because of our desire to use products that are not just portable but unobtrusively wearable, yet powerful enough to be useful that the component technologies such as batteries and processors have been pushed in this directions over the this period. While large bands of radio spectrum space have been allocated to cellular mobile service operators, the intensity of use and the utility of use of radio spectrum peaks in the unlicensed spectrum space used by WiFi and Bluetooth. It could be argued that the economic value of these unlicensed spectrum bands exceeds the exclusively licensed cellular radio systems by orders of magnitude. It could also be argued that the untethering of the last meter of the Internet transformed the Internet, and digital technologies in general, from a specialist pursuit into the consumer product space. In the nineties we used to describe the effort to simplify the use of technology through the term “plug and play”. WiFi was the critical technical development that made that term irrelevant by removing any need for the plug, or the socket for that matter!  

1998 年出现的第二种无线电技术也改变了互联网，可以说它已经变得如此基础，以至于它如此自然地融入我们的环境中，以至于它几乎消失了（改编自马克的引述） Weiser，《21 世纪的计算机》，1997 年）。低功率无线电系统与未经许可的无线电频谱分配或 WiFi 以及随后的蓝牙的结合已经带来了变革。高效电池技术、低功耗运行的计算机芯片以及家庭和办公室最后几米的无线连接的结合彻底改变了我们的技术集体，而这只是因为我们渴望使用不只是便携但不引人注目的可穿戴设备，但功能强大到足以有用，以至于电池和处理器等组件技术在这一时期已朝着这个方向发展。虽然大频段的无线电频谱空间已分配给蜂窝移动服务运营商，但无线电频谱的使用强度和使用效用在 WiFi 和蓝牙使用的非授权频谱空间中达到峰值。可以说，这些未经许可的频段的经济价值超过了独家许可的蜂窝无线电系统几个数量级。也可以说，互联网最后一米的束缚改变了互联网和整个数字技术，从专业追求转向消费产品领域。在九十年代，我们常常通过“即插即用”一词来描述简化技术使用的努力。 WiFi 是一项关键的技术发展，它消除了对插头或插座的任何需要，从而使该术语变得无关紧要！

Mobile data services, WiFi and Bluetooth really revolutionised the Internet, taking it from a “destination you visit” to an “always on utility in your pocket”. The Internet was now a set of applications on a device that went with you everywhere. Always available, always connected, no matter where you might be or what you might be doing. But this was not exactly the full truth. Head out into remote country far enough, or head onto the world’s oceans and your connection options quickly disappeared, leaving only somewhat expensive satellite-based services. These satellite services have been in operation since the early 1960’s, but the high launch costs, limited capacity and the competing interests of terrestrial providers have meant that these services were often operated right at the margins of viability. The best example of this is Motorola’s Iridium project of the late 1990’s, where even before the entire service constellation of satellites was launched, the $5B Iridium project was declared bankrupt. Starlink, a recent entrant in the satellite service area, is using a constellation of some 4,000 low earth orbiting spacecraft and appears so far to have been able to break through this financial barrier. Using reusable launch vehicles, smaller (and lighter) satellites, transponder arrays on board, and a new generation of digital signal processing capabilities, Starlink is in a position to offer retail access services of 100Mbps or more to individual customers. The low altitude of the spacecraft means that the Starlink service competes directly with terrestrial access services in terms of performance. The introduction of inter-spacecraft laser links means that the system is capable of providing a service in any location, and the limiting factor, as with the Iridium effort decades ago, is obtaining the necessary clearances and licenses to have customers located in the respective national geographies. Starlink is certainly revolutionary in terms of capacity, coverage and cost. The questions are whether it is sufficiently revolutionary and whether it can scale up to provide a high-capacity service to hundreds of millions of users. At this point in time these are not easy questions to answer, but the limitations inherent in LEO-based services point to a potential advantage in terrestrial-based access networks. Nevertheless, Starlink is redefining the Internet access market space in many countries, and setting a price performance benchmarks that their terrestrial competitors now have to match.  

移动数据服务、WiFi 和蓝牙真正彻底改变了互联网，将其从“您访问的目的地”转变为“口袋里永远可用的实用工具”。现在，互联网是您随身携带的设备上的一组应用程序。无论您身在何处或正在做什么，始终可用、始终保持联系。但这并不完全是事实。如果前往足够远的偏远国家，或者前往世界海洋，您的连接选项很快就会消失，只留下一些昂贵的卫星服务。这些卫星服务自 1960 年代初就开始运营，但高昂的发射成本、有限的容量以及地面提供商的利益竞争意味着这些服务的运营往往处于生存边缘。最好的例子是摩托罗拉 1990 年代末的铱星项目，甚至在整个卫星服务星座发射之前，价值 50 亿美元的铱星项目就宣布破产。 Starlink 是卫星服务领域的新进入者，它正在使用由约 4,000 个近地轨道航天器组成的星座，迄今为止似乎已经能够突破这一财务障碍。利用可重复使用的运载火箭、更小（更轻）的卫星、机载转发器阵列以及新一代数字信号处理能力，Starlink 能够为个人客户提供 100Mbps 或更高速率的零售接入服务。航天器的低空意味着星链服务在性能方面与地面接入服务直接竞争。 航天器间激光链路的引入意味着该系统能够在任何地点提供服务，与几十年前的铱星项目一样，限制因素是获得必要的许可和许可，以便让客户位于各自的国家/地区。地理。星链在容量、覆盖范围和成本方面无疑是革命性的。问题在于它是否具有足够的革命性，以及是否可以扩展以向数亿用户提供高容量的服务。目前，这些问题并不容易回答，但基于低地球轨道的服务固有的局限性表明了基于地面的接入网络的潜在优势。尽管如此，星链正在重新定义许多国家的互联网接入市场空间，并设定了地面竞争对手现在必须匹配的价格性能基准。  

If we move away from access networks to look at the changes in the “core” of the Internet over the past 25 years, then once more there has been dramatic change. In 1998 the Internet was constructed using the margins of oversupply in the telephone networks. In 1998 the core infrastructure of most Internet Service Providers was still being built by leasing telephone trunk supergroups (E-1 and T-1 circuits, and then E-3 and T-3 as capacity needs escalated, and then OC-1 circuits). While it was not going to stop here, squeezing even more capacity from the network was now proving to be a challenge. 622Mbps IP circuits were being deployed, although many of these were constructed using 155Mbps ATM circuits using router-based load balancing to share the IP load over four of these circuits in parallel. Gigabit circuits were just around the corner, and the initial exercises of running IP over 2.5Gbps SDH circuits were being undertaken in 1998.  

如果我们从接入网的角度来看过去25年互联网“核心”的变化，那么，再次发生了巨大的变化。 1998 年，利用电话网络供过于求的余地构建了互联网。 1998年，大多数互联网服务提供商的核心基础设施仍然是通过租赁电话干线超级组（E-1和T-1电路，然后随着容量需求升级而增加E-3和T-3，然后是OC-1电路）来建设的。虽然事情不会就此停止，但从网络中挤出更多容量现在被证明是一个挑战。正在部署 622Mbps IP 电路，尽管其中许多电路是使用 155Mbps ATM 电路构建的，并使用基于路由器的负载平衡来并行共享其中四个电路的 IP 负载。千兆位电路即将到来，在 2.5Gbps SDH 电路上运行 IP 的初步实践于 1998 年进行。

In some ways 1998 was a pivotal year for IP transmission. Until this time IP was still just one more data application that was positioned as just another customer of the telco’s switched circuit infrastructure. This telco infrastructure was designed and constructed primarily to support telephony. From the analogue voice circuits to the 64K digital circuit through to the higher speed trunk bearers, IP had been running on top of the voice network’s infrastructure. Communications infrastructure connected population centres where there was call volume. The Internet had different demands. Internet traffic patterns did not mirror voice traffic, and IP performance is sensitive to every additional millisecond of delay. Constraining the Internet to the role of an overlay placed on top of a voice network was showing signs of stress, and by 1998 things were changing. The Internet had started to make ever larger demands on transmission capacity, and the driver for further growth in the network’s infrastructure was now not voice, but data. It made little sense to provision an ever-larger voice-based switching infrastructure just to repackage it as IP infrastructure, and by 1998 the industry was starting to consider just what an all-IP high-speed network would look like, building an IP network all the way from the photon in a fibre optic cable all the way through to the design of the Internet application.  

从某些方面来说，1998 年是 IP 传输的关键一年。直到此时，IP 仍然只是又一个数据应用程序，被定位为电信公司交换电路基础设施的另一个客户。该电信基础设施的设计和建造主要是为了支持电话。从模拟语音电路到 64K 数字电路，再到更高速的干线承载，IP 一直运行在语音网络基础设施之上。通信基础设施连接了有呼叫量的人口中心。互联网有不同的需求。互联网流量模式并不反映语音流量，而且 IP 性能对每增加一毫秒的延迟都很敏感。将互联网限制为置于语音网络之上的覆盖层的作用已经显示出压力的迹象，到 1998 年，情况正在发生变化。互联网对传输容量的要求越来越高，网络基础设施进一步增长的驱动力不再是语音，而是数据。仅仅为了将其重新打包为 IP 基础设施而提供越来越大的基于语音的交换基础设施是没有意义的，到 1998 年，业界开始考虑全 IP 高速网络会是什么样子，构建 IP 网络从光纤电缆中的光子一直到互联网应用程序的设计。

At the same time, the fibre optic systems were changing with the introduction of Wave Division Multiplexing (WDM) in fibre systems. Older fibre equipment with electro-optical repeaters and PDH multiplexors allowed a single fibre pair to carry around 560Mbps of data. WDM allowed a fibre pair to carry multiple channels of data using different wavelengths, with each channel supporting a data rate of up to 10Gbps. Channel capacity in a fibre strand was between 40 to 160 wavelength channels using Dense WDM (DWDM). Combined with the use of all-optical amplifiers, the most remarkable part of this entire evolution in fibre systems is that a cable system capable of an aggregate capacity of a terabit per second can be constructed today for much the same cost as a 560Mbps cable system of the mid ’90s. That’s a cost efficiency improvement of a factor of one million in 25 years. The drive to deploy these high capacity DWDM fibre systems was never based on expansion of telephony. The explosive growth of the industry was all to do with supporting the demand for IP. So, it came as no surprise that at the same time as there was increasing demand for IP transmission there was a shift in the transmission model where instead of plugging routers into telco switching gear and using virtual point-to-point circuits for IP, we started to plug routers into wavelengths of the DWDM equipment and operate all-IP networks in the core of the Internet.  

与此同时，随着光纤系统中波分复用 (WDM) 的引入，光纤系统也发生了变化。带有电光中继器和 PDH 多路复用器的老式光纤设备允许单个光纤对传输大约 560Mbps 的数据。 WDM 允许光纤对使用不同波长承载多个数据通道，每个通道支持高达 10Gbps 的数据速率。使用密集 WDM (DWDM) 时，光纤束中的通道容量介于 40 至 160 个波长通道之间。结合全光放大器的使用，光纤系统整个演进中最引人注目的部分是，如今可以以与 560Mbps 电缆系统相同的成本构建每秒总容量为 1 太比特的电缆系统90 年代中期。这意味着 25 年内成本效率提高了 100 万倍。部署这些高容量 DWDM 光纤系统的动力从来都不是基于电话的扩展。该行业的爆炸性增长都与支持IP需求有关。因此，毫不奇怪，随着对 IP 传输的需求不断增加，传输模型也发生了转变，我们不再将路由器插入电信交换设备并使用虚拟点对点电路进行 IP，而是开始将路由器插入DWDM设备的波长中，并在互联网的核心运行全IP网络。

It was not just DWDM that has fundamentally changed these core transmission systems in the past 25 years. Two further technologies have been transformational in the fibre optic area. The first is the use of optical amplifiers. Erbium Doped Fibre Amplifiers provide a highly efficient means of signal amplification without the need to convert the signal back unto a digital form and then passing it back through a digital/analogue converter to modulate the next stage laser driver. This has allowed fibre systems to support terabit per second capacity without necessarily have to integrate terabit per second digital systems. The second fundamental change was a switch in signal modulation from a basic on/off signal into a signal modulation technique that uses signal phase, amplitude and polarity to increase the total capacity of a wavelength within a fibre strand. The key technology here are the digital signal processors (DSPs) and as we improve on the track width of conductor tracks in these DSPs we can increase the gate count on a single chip which allows more complex signal manipulation algorithms to be supported which can be used to increase the sensitivity of the DSP function. In 2010 we were using 40nm track silicon chips in DSPs, supporting Polarization Mode Quadrature Phase Shift Keying (PM-QPSK) which allowed a cable to operate with 100Gbps data rates in a single wavelength, or an aggregated of 8Tbps in a fibre strand. In 2023 DSPs now use 5nm tracks, which can support PCS-144QAM modulation of a base 190Gbaud signal, which can support 2.2Tbps data rates per wavelength, or 105Tbps total capacity per fibre strand. A 12-strand cable would have a total capacity of 1.2Pbs.  

在过去 25 年里，从根本上改变了这些核心传输系统的不仅仅是 DWDM。另外两项技术已经在光纤领域发生了变革。第一个是光放大器的使用。掺铒光纤放大器提供了一种高效的信号放大方法，无需将信号转换回数字形式，然后通过数字/模拟转换器将其传回以调制下一级激光驱动器。这使得光纤系统能够支持太比特每秒的容量，而不必集成太比特每秒的数字系统。第二个根本性变化是信号调制从基本的开/关信号转变为使用信号相位、幅度和极性来增加光纤束内波长总容量的信号调制技术。这里的关键技术是数字信号处理器 (DSP)，随着我们改进这些 DSP 中导体轨道的轨道宽度，我们可以增加单个芯片上的门数，从而支持更复杂的信号处理算法。提高DSP功能的灵敏度。 2010 年，我们在 DSP 中使用 40nm 轨道硅芯片，支持偏振模式正交相移键控 (PM-QPSK)，允许电缆在单个波长中以 100Gbps 数据速率运行，或在光纤束中以 8Tbps 聚合数据速率运行。到 2023 年，DSP 现在使用 5nm 轨道，可支持基本 190Gbaud 信号的 PCS-144QAM 调制，可支持每波长 2.2Tbps 数据速率，或每条光纤束 105Tbps 总容量。 12 股电缆的总容量为 1.2Pbs。

Such very high-performance fibre cable systems are generally used in submarine cable systems to link data centres between continents. In data centre contexts and other terrestrial scenarios, we are now using 200G and 400G per wavelength fibre systems as the common technology base. The major outcome of this is that, in general, transmission is no longer a scarce resource. It is in every sense of the term an abundant commodity. There is no sense in rationing access to communications capacity, be it short or long haul. This is not only a major change in the economic framework of the communications industry, but in phrasing the way in which we use communications. In a scarce system we trend to use “just in time” delivery mechanisms, passing content across the communications system only when it is needed, while an abundant system allows us to use “just in case” delivery mechanisms, which has had a dramatic impact on the architecture of the Internet. Indeed, this extraordinary increase in the underlying capacity of our communications infrastructure through the past 25 years is perhaps the most significant change in the entire landscape of the Internet, as we’ll see when we look at content networking.  

这种非常高性能的光缆系统通常用于海底光缆系统，以连接各大洲之间的数据中心。在数据中心环境和其他地面场景中，我们现在使用每波长 200G 和 400G 光纤系统作为通用技术基础。这样做的主要结果是，总的来说，传输不再是稀缺资源。从任何意义上来说，它都是一种丰富的商品。无论是短途还是长途，对通信容量进行配给是没有意义的。这不仅是通信行业经济框架的重大变化，也是我们使用通信方式的重大变化。在稀缺系统中，我们倾向于使用“及时”交付机制，仅在需要时通过通信系统传递内容，而丰富的系统允许我们使用“以防万一”交付机制，这产生了巨大的影响关于互联网的架构。事实上，过去 25 年里我们的通信基础设施的基础能力的显着增长也许是整个互联网格局中最重大的变化，正如我们在审视内容网络时所看到的那样。

In network operations, we are seeing some stirrings of change, but it appears to be a rather conservative area, and adoption of new network management tools and practices takes time.  

在网络运营方面，我们看到了一些变化，但这似乎是一个相当保守的领域，采用新的网络管理工具和实践需要时间。

The Internet converged on using the Simple Network Management Protocol (SNMP) more than a quarter of a century ago, and despite its security weaknesses, its inefficiency, it’s incredibly irritating use of Abstract Syntax Notation One (ASN.1), and its use in sustaining some forms of Distributed Denial-of-Service (DDoS) attacks, it still enjoys widespread use. But SNMP is only a network monitoring protocol, not a network configuration protocol, as anyone who has attempted to use SNMP write operations can attest. The more recent Network Configuration Protocol (NETCONF) and the Yet Another Next Generation (YANG) data modelling language are attempting to pull this area of configuration management into something a little more usable than Command-Line Interface (CLI) scripts driving interfaces on switches.  

二十多年前，互联网集中使用简单网络管理协议 (SNMP)，尽管存在安全漏洞、效率低下，但抽象语法符号一 (ASN.1) 的使用及其在它可以承受某些形式的分布式拒绝服务 (DDoS) 攻击，但仍然得到广泛使用。但 SNMP 只是一个网络监控协议，而不是一个网络配置协议，任何尝试过使用 SNMP 写入操作的人都可以证明这一点。最近的网络配置协议 (NETCONF) 和又一个下一代 (YANG) 数据建模语言正在尝试将配置管理的这一领域引入比驱动交换机上的接口的命令行界面 (CLI) 脚本更有用的东西。

At the same time, we are seeing orchestration tools such as Ansible, Chef, Network Automation and Programmability Abstraction Layer with Multivendor (NAPALM) and SALT enter the network operations space, permitting the orchestration of management tasks over thousands of individual components. These network operations management tools are welcome steps forward to improve the state of automated network management, but it’s still far short of a desirable endpoint. The desired endpoint of a fully automated network management framework is still far from our reach. Surely it must be feasible to feed an adaptive autonomous control system with the network infrastructure and available resources, and allow the control system to monitor the network and modify the operating parameters of network components to continuously meet the service-level objectives of the network? Where’s the driverless car for driving networks? Maybe the next 10 years might get us there.  

与此同时，我们看到 Ansible、Chef、网络自动化和多供应商可编程性抽象层 (NAPALM) 和 SALT 等编排工具进入网络运营领域，允许编排数千个单独组件的管理任务。这些网络运营管理工具是改善自动化网络管理状态的值得欢迎的一步，但它仍然远未达到理想的终点。完全自动化的网络管理框架的理想终点仍然距离我们遥不可及。为自适应自主控制系统提供网络基础设施和可用资源，并允许控制系统监控网络并修改网络组件的操作参数以持续满足网络的服务水平目标，这肯定是可行的吗？驱动网络的无人驾驶汽车在哪里？也许未来10年我们就能实现这一目标。

### The Internet Layer 互联网层

If our transmission systems have been subject to dramatic changes in the past quarter century, then what’s happened at the IP layer over the same period?  

如果说我们的传输系统在过去25年里发生了巨大的变化，那么同期IP层发生了什么？

Firstly, we need to consider the elephant in the Internet layer room. There was one fundamental change at the Internet level of the protocol stack that was meant to have all happened some twenty years ago, and that’s the transition to IP version 6. Twenty-five years ago, in 1998, we were forecasting that we would’ve consumed all the remaining unallocated IPv4 addresses by around 2025. That gave us slightly more than 25 years, so there was no particular sense of urgency. We didn’t need to ring the emergency bell or raise any alarms. The overall aim was to proceed in an orderly manner. Things took a different course because we failed to appreciate the true impact of the shift of the Internet to mobile devices. All of a sudden, we were dealing with an Internet with billions of users, using billions of new mobile devices, and our comfortable predictions of a stately and steady rundown of the IPv4 address pools was thrown out of the window about as quickly as you could say the word “iPhone”. From “all the time in the world” we swung to “no time left to do anything” within a single year. In the five-year period, when mobile services exploded in volume, between 2005 and 2010, the total count of allocated IP addresses rose from 1.5B addresses to 3.1B, from a total address pool of 3.7B addresses. The network had doubled in size, and the time left to complete the transition had shrunk from more than twenty years to a little over one!  

首先，我们需要考虑互联网层房间里的大象。协议栈的互联网层面发生了一个根本性的变化，这一切本应在大约二十年前发生，那就是向 IP 版本 6 的过渡。二十五年前，即 1998 年，我们预测我们会“到 2025 年左右，我们已经耗尽了所有剩余的未分配 IPv4 地址。这给了我们 25 年多一点的时间，因此没有特别的紧迫感。我们不需要按紧急铃或发出任何警报。总体目标是有序推进。事情发生了不同的变化，因为我们没有意识到互联网向移动设备转变的真正影响。突然间，我们面对的是拥有数十亿用户、使用数十亿新移动设备的互联网，我们对 IPv4 地址池庄严而稳定的耗尽的舒适预测很快就被抛到了九霄云外。说“iPhone”这个词。一年之内，我们从“世界上所有的时间”转变为“没有时间做任何事”。在移动业务量爆发式增长的五年期间，从2005年到2010年，分配的IP地址总数从1.5B地址增加到3.1B地址，地址池总数为3.7B。网络规模扩大了一倍，完成转变的时间也从二十多年缩短到了一年多一点！

At that point all the plans for an orderly transition were thrown out, and many network administrators scrambled to obtain IPv4 addresses, which further depleted IPv4 pools. The central pool of IPv4 addresses, operated by the IANA, was exhausted in February 2011. APNIC depleted its IPv4 pool in April of that year, the RIPE NCC 18 months later, LACNIC in 2014 and ARIN in 2015. We had expected that this situation would motivate network operators to hasten their plans for IPv6 deployment, yet, perversely, this was not the case. Less than 1% of the Internet’s user base were using IPv6 in 2011. Five years later, as each of the RIRs ran down their remaining pools of IPv4 addresses, this internet-wide IPv6 user count had increased to just 5%. In 2023 the process is still underway and only some 35% of the Internet’s user base has IPv6 capability. I’m not sure anyone is willing to predict how long this anomalous situation of running the IPv4 Internet on an empty tank will persist.  

那时，所有有序过渡的计划都被抛弃了，许多网络管理员争先恐后地获取 IPv4 地址，这进一步耗尽了 IPv4 池。由 IANA 运营的中央 IPv4 地址池于 2011 年 2 月耗尽。APNIC 于当年 4 月耗尽了其 IPv4 池，RIPE NCC 于 18 个月后耗尽，LACNIC 于 2014 年耗尽，ARIN 于 2015 年耗尽。我们预料到这种情况会发生。这将激励网络运营商加快 IPv6 部署计划，但反常的是，事实并非如此。 2011 年，只有不到 1% 的互联网用户群使用 IPv6。五年后，随着每个 RIR 耗尽剩余的 IPv4 地址池，互联网范围内的 IPv6 用户数量仅增加到 5%。到 2023 年，这一过程仍在进行中，只有约 35% 的互联网用户群具备 IPv6 能力。我不确定是否有人愿意预测这种在空罐上运行 IPv4 互联网的异常情况会持续多久。

How has the Internet managed to continue to operate, and even grow, without a supply of new IPv4 addresses? In a word, the answer is “NATs”. While the Network Address Translator (NAT) concept received little fanfare when it was first published, it has enjoyed massive deployment over the past 25 years, and today NATs are ubiquitous. The application architecture of the Internet has changed, and we are now operating a client/server framework. Servers have permanent IP addresses, while clients “borrow” a public IPv4 address to complete a transaction and return it back to a common pool when they are done. Time-sharing IP addresses, and also using the 16-bit source port field in TCP and UDP, has managed to extend the quasi-IPv4 address space by up to 20 bits, making the IPv4+NAT address space up to a million times larger than the original 32-bit IPv4 address space. In practice, the story is a little more involved than that, and some very large service providers have reached logistical limits in using NATs compensate the exhaustion of IPv4 addresses. This situation has motivated them to transition to a dual stack mode of operation, and they are relaying on a dual stack host behaviour that prefers to use IPv6 when possible, so the dual stack deployment relieves the pressure on the IPv4 NAT functions.  

在没有新的 IPv4 地址供应的情况下，互联网如何能够继续运行甚至发展？简而言之，答案就是“NAT”。虽然网络地址转换器 (NAT) 概念首次发布时并未引起多大关注，但它在过去 25 年中得到了大规模部署，如今 NAT 已无处不在。互联网的应用架构已经改变，我们现在运行的是客户端/服务器框架。服务器拥有永久 IP 地址，而客户端则“借用”公共 IPv4 地址来完成交易，并在完成后将其返回到公共池。分时IP地址，并利用TCP和UDP中的16位源端口字段，成功地将准IPv4地址空间扩展了多达20位，使IPv4+NAT地址空间扩大了100万倍比原来的 32 位 IPv4 地址空间。实际上，情况比这更复杂一些，一些非常大的服务提供商在使用 NAT 补偿 IPv4 地址的耗尽时已经达到了逻辑限制。这种情况促使他们过渡到双栈操作模式，并且他们正在中继双栈主机行为，在可能的情况下更喜欢使用 IPv6，因此双栈部署减轻了 IPv4 NAT 功能的压力。

NATs have prompted a significant change at the IP level in changing the default assumption about the semantics of an IP address. An IP address is no longer synonymous with the persistent identity of the remote party but has assumed the role of an ephemeral session token. The leisurely pace of the IPv6 transition is partly due to this altered role of addresses, as we no longer require every connected device to have a persistently assigned globally unique IP address.  

NAT 促使 IP 级别发生重大变化，改变了有关 IP 地址语义的默认假设。 IP 地址不再是远程方持久身份的同义词，而是承担临时会话令牌的角色。 IPv6 过渡的缓慢节奏部分是由于地址角色的改变，因为我们不再要求每个连接的设备都拥有永久分配的全球唯一 IP 地址。

IPv6 and NATs are not the only areas of activity in the Internet layer in the past 25 years. We’ve tried to change many parts of the Internet layer, but few, if any, of the proposed changes have managed to gain any significant traction out there in the network. The functions performed at the internet layer of the protocol stack are no different from those of 25 years ago. IP Mobility, Multicast and IP Security (IPSec) are largely Internet layer technologies that have failed to gain significant levels of traction in the marketplace of the public Internet.  

IPv6 和 NAT 并不是过去 25 年中互联网层的唯一活动领域。我们尝试过改变互联网层的许多部分，但所提议的改变中很少有（如果有的话）能够在网络中获得任何显着的吸引力。协议栈互联网层执行的功能与25年前没有什么不同。 IP 移动性、组播和 IP 安全 (IPSec) 主要是互联网层技术，但未能在公共互联网市场中获得显着的吸引力。

Quality of Service (QoS) was a hot topic in 1998, and it involved the search for a reasonable way for some packets to take some form of expedited path across the network, while other packets took an undifferentiated path. We experimented with various forms of signalling, packet classifiers, queue management algorithms and interpretations of the Type of Service bits in the IPv4 packet header, and we explored the QoS architectures of Integrated and Differentiated Services in great detail. However, QoS never managed to get a toehold into mainstream Internet service environments. In this case the Internet took a simpler direction, and in response to not enough network capacity, we just augmented the network to meet demand. Again, this is an aspect of the altered mindset when the communication system shifts from scarcity and rationing to one of abundance. We’ve given up installing additional intricate mechanisms in the network, in host protocol stacks and even in applications to negotiate how to share insufficient network capacity. So far, the simple approach just adding more capacity to the network has prevailed, and QoS remains largely unused.  

服务质量 (QoS) 是 1998 年的热门话题，它涉及寻找一种合理的方式，让某些数据包在网络中采取某种形式的快速路径，而其他数据包则采取无差别的路径。我们尝试了各种形式的信令、数据包分类器、队列管理算法以及 IPv4 数据包标头中服务类型位的解释，并详细探索了集成服务和差异化服务的 QoS 架构。然而，QoS始终未能在主流互联网服务环境中站稳脚跟。在这种情况下，互联网走向了更简单的方向，针对网络容量不够的情况，我们只是对网络进行扩容来满足需求。同样，当通信系统从稀缺和配给转向丰富时，这是心态改变的一个方面。我们已经放弃在网络、主机协议栈甚至应用程序中安装额外的复杂机制来协商如何共享不足的网络容量。到目前为止，仅向网络添加更多容量的简单方法已经盛行，并且 QoS 仍然基本上未被使用。

The switch from circuit switching to packet switching has never managed to achieve universal acceptance. We’ve experimented with putting circuits back into the IP datagram architecture in various ways, most notably with the Multi-Protocol Label Switching (MPLS) technology. This technology used the label swapping approach that was previously used in X.25, Frame Relay and ATM virtual circuit switching systems, and created a collection of virtual paths from each network ingress to each network egress across the IP network. The original idea was that in the interior of the network you no longer needed to load up a complete routing table into each switching element, and instead of performing destination address lookup you could perform a much smaller, and hopefully faster, label lookup. This performance differentiator did not eventuate and switching packets using the 32-bit destination address in a fully populated forwarding table continued to present much the same level of cost efficiency at the hardware level as virtual circuit label switching. However, there is one aspect of MPLS and similar approaches that has proved to be invaluable for many network operators. A general-purpose network utility has many disparate client networks, and a single packet-switched environment does not allow the network operator to control the way in which the common network resource is allocated to each client network. It also does not readily support segmentation of reachability. Virtual circuit overlays, such as MPLS provide mechanisms to control resource allocation and constrain cross-network leakage, and for many network operators these are adequate reasons to head down an MPLS-like path for their network platform.  

从电路交换到分组交换的转变从未获得普遍接受。我们尝试以各种方式将电路放回到 IP 数据报架构中，最引人注目的是多协议标签交换 (MPLS) 技术。该技术使用了以前在 X.25、帧中继和 ATM 虚拟电路交换系统中使用的标签交换方法，并创建了跨 IP 网络从每个网络入口到每个网络出口的虚拟路径集合。最初的想法是，在网络内部，您不再需要将完整的路由表加载到每个交换元件中，并且您可以执行更小且希望更快的标签查找，而不是执行目标地址查找。这种性能差异并没有最终实现，并且在完全填充的转发表中使用 32 位目标地址交换数据包继续在硬件级别上呈现与虚拟电路标签交换大致相同水平的成本效率。然而，MPLS 和类似方法的一个方面已被证明对许多网络运营商来说是无价的。通用网络设施具有许多不同的客户端网络，并且单个分组交换环境不允许网络运营商控制将公共网络资源分配给每个客户端网络的方式。它也不容易支持可达性分段。虚拟电路覆盖（例如 MPLS）提供了控制资源分配和限制跨网络泄漏的机制，对于许多网络运营商来说，这些都是为其网络平台选择类似 MPLS 的路径的充分理由。

Moving sideways at this level of the protocol stack we probably should look at the evolution of routing technologies. The early ’90s saw a flurry of activity in the routing space, and various routing protocols were quickly developed and deployed. By 1998 the conventional approach to routing was the use of either IS-IS or OSPF as the interior routing protocol, and BGP-4 as the inter-domain routing protocol. This picture has remained constant right up to today. In some ways it reassuring to see a basic technology that is capable of sustaining a quite dramatic growth rate through many years of scaling, but in other ways it is less reassuring to see that the unresolved issues we had with the routing system in 1998 are largely still with us today.  

在协议栈的这一级别上，我们可能应该看看路由技术的演变。 20 世纪 90 年代初，路由领域出现了一系列的活动，各种路由协议得到了快速开发和部署。到 1998 年，传统的路由方法是使用 IS-IS 或 OSPF 作为内部路由协议，并使用 BGP-4 作为域间路由协议。直到今天，这张照片仍然保持不变。从某些方面来说，看到一项基本技术能够通过多年的扩展来维持相当惊人的增长率是令人放心的，但从其他方面来说，看到我们在 1998 年路由系统中遇到的未解决的问题主要是今天仍然和我们在一起。

The largest of these unresolved issues lie in the trust we place in the Internet’s inter-domain routing system. There is no overall orchestration of the Internet’s routing system. Each network advertises reachability information to its adjacent networks and selects what it regards as the “best” reachability information from the set received from these same network peers. This mutual trust that each network places in all other networks can, and has, been abused in various ways. The effort to allow each routing entity to distinguish between what is a “correct” item of routing information and what is “false” route has a rich history of initiatives that have faltered for one reason or another. The most recent effort in this space is built upon the foundations of the number system and uses the association of a public/private key pair with the current holders of addresses and autonomous system numbers. This allows these holders to issue signed authorities about the use of these number resources in the context of routing, and by coupling these authorities with the information being propagated in the routing system, it is intended that unauthorized use cases can be detected. This effort, the Resource Public Key Infrastructure (RPKI) has achieved some level of acceptance in the networking space, and in 2023 around one third of all route objects have associated RPKI credentials. The work is still “in progress” as the more challenging aspect of this work is to associate verifiable credentials with a route’s propagation through the network that does not impose onerous burdens on the routing system and is not overly fragile in its operation. The extended period where the routing system has operated in an essentially untrustable state has prompted the application layer to generate their own mechanisms of trust. These days it’s largely left to the Transport Layer Security (TLS) protocol to determine whether a client has reached its intended server. Given that we’ve been unable to construct a secured routing system for many decades, the question arises whether there is still the same level of need for such a system that we had some 25 years ago given that the application space sees this as a largely solved problem through the close to ubiquitous use of TLS.  

这些未解决的问题中最大的问题在于我们对互联网域间路由系统的信任。互联网的路由系统没有整体的编排。每个网络向其相邻网络通告可达性信息，并从从这些相同网络对等点接收到的集合中选择它认为“最佳”的可达性信息。每个网络在所有其他网络中建立的这种相互信任可能并且已经以各种方式被滥用。允许每个路由实体区分什么是“正确”路由信息项和什么是“错误”路由的努力有着丰富的历史，但由于这样或那样的原因而动摇了。该领域的最新成果建立在数字系统的基础上，并使用公钥/私钥对与当前地址和自治系统号码持有者的关联。这允许这些持有者发布有关在路由上下文中使用这些号码资源的签名权限，并且通过将这些权限与路由系统中传播的信息相结合，可以检测到未经授权的用例。这项工作，资源公钥基础设施 (RPKI) 已在网络空间中获得了一定程度的认可，到 2023 年，大约三分之一的路由对象都具有关联的 RPKI 凭证。这项工作仍在“进行中”，因为这项工作更具挑战性的方面是将可验证的凭证与通过网络的路由传播相关联，这不会给路由系统带来繁重的负担，并且在其运行中也不会过于脆弱。 路由系统长期处于不可信状态，促使应用层产生自己的信任机制。如今，很大程度上由传输层安全 (TLS) 协议来确定客户端是否已到达其预期服务器。鉴于我们几十年来一直无法构建安全的路由系统，问题就出现了，考虑到应用程序领域将其视为一个主要的解决方案，对这样一个系统的需求是否仍然像大约 25 年前一样水平。通过几乎无处不在的 TLS 使用解决了问题。

This tension between the Internet layer and the upper layers of the protocol stack is also evident in the way in which we have addressed the perennial issue of location and identity. One of the original simplifications in the IP architecture was to bundle the semantics of identity, location and forwarding into an IP address. While that has proved phenomenally effective in terms of simplicity of applications and simplicity of IP networks, it has posed some serious challenges when considering mobility, routing, protocol transition and network scaling. Each of these aspects of the Internet would benefit considerably if the Internet architecture allowed identity to be distinct from location. Numerous efforts have been directed at this problem over the past decade, particularly in IPv6, but so far, we really haven’t arrived at an approach that feels truly comfortable in the context of IP. The problem we appear to have stuck on for the past decade is that if we create a framework of applications that use identity as a rendezvous mechanism and use an IP layer that requires location, then how is the mapping between identity and location distributed in an efficient and suitably robust manner? The transport layer of the protocol stack has also looked at the same space and come up with some interesting approaches as we will see in the next section.  

互联网层和协议栈上层之间的这种紧张关系在我们解决长期存在的位置和身份问题的方式中也很明显。 IP 架构中最初的简化之一是将身份、位置和转发的语义捆绑到 IP 地址中。虽然这在应用程序的简单性和 IP 网络的简单性方面已被证明非常有效，但在考虑移动性、路由、协议转换和网络扩展时，它也带来了一些严峻的挑战。如果互联网架构允许身份与位置不同，那么互联网的每个方面都将受益匪浅。在过去的十年里，我们针对这个问题做出了许多努力，特别是在 IPv6 方面，但到目前为止，我们确实还没有找到一种在 IP 环境中真正令人满意的方法。过去十年来我们似乎一直坚持的问题是，如果我们创建一个使用身份作为集合机制并使用需要位置的 IP 层的应用程序框架，那么身份和位置之间的映射如何以有效的方式分布以及适当稳健的方式？协议栈的传输层也研究了相同的空间，并提出了一些有趣的方法，我们将在下一节中看到。

### Transport 运输

Back in 1998 the transport layer of the IP architecture consisted of UDP and TCP, and the network use pattern was around 95% TCP and 5% UDP. It’s taken all of the intervening twenty-five years but this picture has finally changed.  

早在 1998 年，IP 架构的传输层由 UDP 和 TCP 组成，网络使用模式约为 95% TCP 和 5% UDP。这花了整整二十五年的时间，但这幅图景终于改变了。

We’ve developed some new transport protocols in their period, such as the Datagram Congestion Control Protocol (DCCP) and the Stream Control Transmission Protocol (SCTP) which can be regarding as refinements of TCP to extend a flow control mechanism to apply to datagram streams in the case of DCCP and a shared flow control state over multiple reliable streams in the case of SCTP. However, in a world of transport-aware middleware that has been a constant factor over this period, the level of capability to actually deploy these new protocols in the public Internet is marginal at best. These more recent transport protocols are not recognised by firewalls, NATs and similar, and as a result, the prospects of widescale deployment of such protocols in the public Internet are not terribly good We seem to be firmly stuck in a world of TCP and UDP.  

在此期间我们开发了一些新的传输协议，例如数据报拥塞控制协议（DCCP）和流控制传输协议（SCTP），它们可以被视为TCP的改进，以扩展流量控制机制以应用于数据报流在 DCCP 的情况下，在 SCTP 的情况下在多个可靠流上共享流控制状态。然而，在这一时期一直存在的传输感知中间件世界中，在公共互联网中实际部署这些新协议的能力水平充其量也只是微不足道的。这些较新的传输协议不被防火墙、NAT 和类似协议所识别，因此，在公共互联网中大规模部署此类协议的前景并不是很好。我们似乎牢牢地陷入了 TCP 和 UDP 的世界中。

TCP has proved to be remarkably resilient over the years, but as the network increases in capacity the ability of TCP to continue to deliver ever faster data rates over distances that span the globe is becoming a significant issue. There has been much work to revise the TCP flow control algorithms so that they still share the network fairly with other concurrent TCP sessions yet can ramp up to multi-gigabit per second data transfer rates and sustain that rate over extended periods. The mainstream TCP flow control protocol has been shifting from the conventional RENO-styled protocol to CUBIC. CUBIC attempts to find a stable sending rate and then slowly add flow pressure to the network path to see if greater sending rates can be supported by the network. The response to packet drop remains a dramatic rate drop, but not quite as dramatic as the rate halving of Reno, but nevertheless it is still a drop-sensitive ack-paced flow control protocol.  

多年来，TCP 已被证明具有显着的弹性，但随着网络容量的增加，TCP 继续在全球范围内提供更快数据速率的能力正在成为一个重大问题。人们已经做了很多工作来修改 TCP 流控制算法，以便它们仍然与其他并发 TCP 会话公平地共享网络，同时可以提高到每秒数千兆位的数据传输速率，并在较长时间内维持该速率。主流的TCP流控协议已经从传统的RENO风格的协议转向CUBIC风格的协议。 CUBIC尝试找到一个稳定的发送速率，然后慢慢向网络路径增加流量压力，看看网络是否可以支持更大的发送速率。对数据包丢失的响应仍然是急剧的速率下降，但不如 Reno 的速率减半那么剧烈，但尽管如此，它仍然是一个对丢弃敏感的确认节奏流量控制协议。

However, the picture has changed with the introduction of the BBR protocol. Driving the network into the point not only of network queue formation, but right to the point of queue overflow and packet loss is a crude approach. The problem here is that packet loss represents a loss of feedback, and in a feedback-based flow control protocol, this loss of feedback pushes the protocol into a space where it has to pull back its sending rate to re-establish a signal flow. BBR represents a different way of looking at flow control, and BBR attempts to drive the flow to the point of the onset of queue formation in the network rather than aiming at the point of queue collapse. This reduces the latency of the flow and reduces the cost of network switching equipment by reducing the very highspeed fast memory buffer requirements.  

然而，随着 BBR 协议的引入，情况发生了变化。不仅将网络驱动到形成网络队列的点，而且直接导致队列溢出和数据包丢失的点是一种粗略的方法。这里的问题是，数据包丢失代表了反馈的丢失，并且在基于反馈的流控制协议中，这种反馈的丢失将协议推入必须拉回其发送速率以重新建立信号流的空间。 BBR 代表了一种不同的流量控制方式，BBR 尝试将流量驱动到网络中队列形成的开始点，而不是瞄准队列崩溃点。这减少了流的延迟，并通过减少非常高速的快速内存缓冲区需求来降低网络交换设备的成本。

This is not the only area of experimentation in changing the TCP congestion control paradigm. Another approach is being explored in the Low Latency Low Loss Scalable throughput initiative (L4S) which is looking at incorporating network signals into the flow control algorithm. Here the network’s packet switches write into the packet header when standing queues start to form, using the packet’s congestion experienced indication (ECN) signal in the IP header. The receiver of this signal is expected to back off its sending rate in a manner similar to packet loss. The advantage of this approach is that there is no loss of feedback signalling, and the flow reacts to the formation of congestion conditions rather than the end point of queue collapse. However, ECN requires the deployment of ECN-marking equipment, and the effort of synchronising network equipment and transport protocol behaviours is far greater when compared to protocol-only approaches such as BBR.  

这并不是改变 TCP 拥塞控制范式的唯一实验领域。低延迟低损耗可扩展吞吐量计划 (L4S) 正在探索另一种方法，该计划着眼于将网络信号合并到流量控制算法中。当站立队列开始形成时，网络的数据包交换机使用 IP 标头中数据包的拥塞经历指示 (ECN) 信号写入数据包标头。该信号的接收器预计会以类似于丢包的方式降低其发送速率。这种方法的优点是不会丢失反馈信令，并且流对拥塞条件的形成而不是队列崩溃的终点做出反应。然而，ECN需要部署ECN标记设备，并且与BBR等仅协议方法相比，同步网络设备和传输协议行为的工作量要大得多。

There have been some other initiatives in the transport space which are also worthy of note.  

运输领域还有一些其他举措也值得注意。

The first of these is Multipath TCP. The observation here is based around the increasing ubiquity of both WiFi and cellular radio services, and the configuration of most mobile devices to include the ability to access both of these networks. In general, the choice of which network interface to use is a single decision made by the mobile platform for all active applications. When a usable WiFi network is detected, the device will prefer to use that connection for all new connections as it is assumed that the WiFi service will be cheaper for the user and operate at a higher performance level. But if performance is an issue, and resilience is an issue, then can we allow a TCP session to use all the available networks at once, and optimise its use of these multiple network paths to the destination such that the total data throughput is optimised? This is the objective of Multipath TCP, where a single TCP session is broken into a number of sub-sessions, where each sub-session uses a different network path by using a different local network interface. This allows separate TCP states to control the flows passing across each network path to optimise throughput. It also can permit flow migration, allowing a logical TCP flow to switch from one network path to another while preserving integrity. The interesting aspect of this behaviour is that the control of the multipath behaviours is, in the first instance, under the control of the application rather than the host platform. This was an early response to the recognition of increasing capacity and diversity in edge networks, and how we could respond to this situation at the transport session level.  

第一个是多路径 TCP。这里的观察基于 WiFi 和蜂窝无线电服务的日益普及，以及大多数移动设备的配置，包括访问这两个网络的能力。一般来说，选择使用哪个网络接口是移动平台为所有活动应用程序做出的单一决定。当检测到可用的 WiFi 网络时，设备将优先使用该连接来进行所有新连接，因为它假定 WiFi 服务对于用户来说会更便宜并且以更高的性能水平运行。但是，如果性能是一个问题，并且弹性是一个问题，那么我们是否可以允许 TCP 会话同时使用所有可用网络，并优化其对到达目的地的多个网络路径的使用，从而优化总数据吞吐量？这是多路径 TCP 的目标，其中单个 TCP 会话被分成多个子会话，其中每个子会话通过使用不同的本地网络接口来使用不同的网络路径。这允许单独的 TCP 状态控制通过每个网络路径的流量以优化吞吐量。它还可以允许流迁移，允许逻辑 TCP 流从一个网络路径切换到另一个网络路径，同时保持完整性。这种行为的有趣之处在于，多路径行为的控制首先是在应用程序而不是主机平台的控制之下。这是对边缘网络容量不断增加和多样性的认识的早期回应，以及我们如何在传输会话级别应对这种情况。

The second initiative, which for me is a fundamental change in transport capabilities and functions, is the introduction of the QUIC protocol. At its simplest level you could say QUIC is a packaging of the combination TCP and TLS into a UDP wrapping. However, I would suggest that such a description is well short of the mark. QUIC is in many ways a far more ambitious transport protocol, bringing transport to the point where it is better suited to the current application behaviour. QUIC is intended to improve the transport performance for encrypted traffic with faster session setup. QUIC allows for further evolution of transport mechanisms with support for remote procedure calls (RPC). QUIC also has integral support for concurrent session multiplexing that avoids TCP’s head of line blocking. QUIC encrypts the payload data, but unlike TLS QUIC also encrypts the control data (the equivalent of the TCP header) and explicitly avoids the emerging TCP ossification within the network by occluding the entirety of the session’s control exchange from the network. QUIC is address agile, in that it can react to network-level address renumbering in an active QUIC session, as can occur with the presence of NATs on the network path. QUIC can be implemented in user space, so applications can control their own transport functions. There is no longer a dependence on the platform in terms of the quality of the implementation of the transport service. With QUIC the application exercises a comprehensive level of control of the way the application interacts with the network.  

第二项举措对我来说是传输能力和功能的根本性改变，是引入 QUIC 协议。在最简单的层面上，您可以说 QUIC 是将 TCP 和 TLS 组合打包到 UDP 包装中。然而，我认为这样的描述是远远不够的。从很多方面来说，QUIC 都是一个更加雄心勃勃的传输协议，它使传输更加适合当前的应用程序行为。 QUIC 旨在通过更快的会话设置来提高加密流量的传输性能。 QUIC 允许传输机制进一步发展并支持远程过程调用 (RPC)。 QUIC 还全面支持并发会话复用，避免 TCP 的队头阻塞。 QUIC 加密有效负载数据，但与 TLS 不同的是，QUIC 还加密控制数据（相当于 TCP 标头），并通过阻止来自网络的整个会话控制交换来明确避免网络内出现的 TCP 僵化。 QUIC 是地址敏捷的，因为它可以对活动 QUIC 会话中的网络级地址重新编号做出反应，就像网络路径上存在 NAT 时可能发生的那样。 QUIC 可以在用户空间中实现，因此应用程序可以控制自己的传输功能。运输服务的实施质量不再依赖平台。通过 QUIC，应用程序可以对应用程序与网络交互的方式进行全面的控制。

There are a number of lessons to be drawn from the QUIC experience. Any useful public communications medium needs to safeguard the privacy and integrity of the communications that it carries. The time when open protocols represented an acceptable compromise between efficiency, speed and privacy are over and these days all network transactions in the public Internet need to be protected by adequate encryption. QUIC’s model of wrapping a set of transactions including both data and control transactions between a client and a server into an end-to-end encryption state represents a minimum level of functionality in today’s networking environment.  

从 QUIC 的经验中可以吸取许多教训。任何有用的公共通信媒介都需要保护其所承载的通信的隐私性和完整性。开放协议代表效率、速度和隐私之间可接受的妥协的时代已经结束，如今公共互联网中的所有网络交易都需要通过足够的加密来保护。 QUIC 的模型将客户端和服务器之间的一组事务（包括数据和控制事务）包装成端到端加密状态，代表了当今网络环境中的最低功能级别。

Secondly, QUIC provides needed additional transport functionality. TCP and UDP represent just two points of transport functions within a broader spectrum of possible transport models. UDP is just too susceptible to abuse, so we’ve heaped everything onto TCP. The issue is TCP was designed as an efficient single streaming protocol and retro-fitting multiple sessions, short transactions, remote procedure calls, reliable single packet transactions, and shared congestion states have proved to be impossible to implement in TCP.  

其次，QUIC 提供了所需的额外传输功能。 TCP 和 UDP 仅代表更广泛的可能传输模型中的两个传输功能点。 UDP 太容易被滥用，因此我们将所有内容都堆放在 TCP 上。问题是 TCP 被设计为高效的单一流协议，并且改进的多会话、短事务、远程过程调用、可靠的单数据包事务和共享拥塞状态已被证明不可能在 TCP 中实现。

Applications are now dominant in the Internet ecosystem, while platforms and networks are being commoditised. We are seeing losing patience with platforms providing common transport services for the application that they host, and a new model where the application comes with its own transport service. Taking an even broader perspective, the context of the Internet’s success lay in shifting the responsibility for providing service from the network to the end system. This allowed us to make more efficient use of the common network substrate and push the cost of this packetization of network transactions over to end systems. It shifted the innovation role from the large and lumbering telco operators into the more nimble world of software. QUIC takes this one step further, and pushes the innovation role from platforms to applications, just at the time when platforms are declining in relative importance within the ecosystem. From such a perspective the emergence of an application-centric transport model that provides faster services, a larger repertoire of transport models and encompassing comprehensive encryption was an inevitable development.  

应用程序现在在互联网生态系统中占据主导地位，而平台和网络正在商品化。我们看到，人们对为其托管的应用程序提供通用传输服务的平台以及应用程序自带传输服务的新模式失去了耐心。从更广阔的角度来看，互联网成功的背景在于将提供服务的责任从网络转移到终端系统。这使我们能够更有效地利用公共网络底层，并将网络事务分组化的成本转移到终端系统。它将创新角色从笨重的大型电信运营商转移到了更加灵活的软件世界。 QUIC 更进一步，将创新作用从平台推向应用程序，而此时平台在生态系统中的相对重要性正在下降。从这个角度来看，以应用程序为中心的传输模型的出现是必然的发展，它提供更快的服务、更大的传输模型库并包含全面的加密。

We have pushed the responsibility for end-to-end authentication into the transport layer with the close to ubiquitous TLS. TLS layers itself above TCP (or merges with the TCP-like function in the case of QUIC) and the client passes the name of the service it intends to connect with to the remote server. The server passes its public key to the client, and the client authenticates this key using its own trust anchors. The server and client then negotiate a session key and proceed with an encrypted session. TLS is robust in almost every respect. The major weakness lies in the highly distributed trust model where there are hundreds of different operators of trusted credentials (certification authorities) and thousands of various registration agents. These entities are placed in a highly trusted role, and they can never lie. The problem is that they have proved to be corruptible from time to time. They typically operate using online services and a successful attack against such platforms can be abused to allow the issuance of trusted public certificates. We have invested considerable time and effort in shoring up this trust framework, but at the same time we’ve been working to make these public key certificates a commodity rather than an expensive luxury. The introduction of free certification authorities has succeeded in making these certificates available to all, but at the same time the totally automated certificate issuance process is liable to various forms of abuse. Despite these considerations we’ve placed the entirety of the burden of service authenticity and session encryption onto TLS, to the point that other related efforts, such as IPSEC, BGP routing security and DNSSEC in the DNS, are generally perceived as optional extras rather than basic essentials to be included the security toolkit.  

我们通过几乎无处不在的 TLS 将端到端身份验证的责任推入了传输层。 TLS 将自身置于 TCP 之上（或者在 QUIC 的情况下与类似 TCP 的功能合并），并且客户端将其打算连接的服务的名称传递给远程服务器。服务器将其公钥传递给客户端，客户端使用自己的信任锚来验证该密钥。然后，服务器和客户端协商会话密钥并继续加密会话。 TLS 几乎在各个方面都很强大。主要弱点在于高度分布式的信任模型，其中有数百个不同的受信任凭证运营商（认证机构）和数千个不同的注册代理。这些实体被置于高度信任的角色，他们永远不会说谎。问题是它们有时会被证明是容易腐败的。它们通常使用在线服务进行操作，对此类平台的成功攻击可能会被滥用以允许颁发受信任的公共证书。我们投入了大量的时间和精力来支撑这个信任框架，但同时我们也一直在努力使这些公钥证书成为一种商品，而不是一种昂贵的奢侈品。免费证书颁发机构的引入成功地使所有人都可以使用这些证书，但与此同时，完全自动化的证书颁发过程容易受到各种形式的滥用。 尽管有这些考虑，我们还是将服务真实性和会话加密的全部负担都放在了 TLS 上，以至于其他相关工作，例如 IPSEC、BGP 路由安全和 DNS 中的 DNSSEC，通常被视为可选的额外功能，而不是安全工具包中包含的基本要素。

### Applications and Services  

应用程序和服务

This layer has also seen quite profound changes over the past quarter century, tracking the progress of increasing technical capability and increasing consumer demands. In the late 1990’s the Internet was on the cusp of portal mania, where Look Smart was the darling of the Internet boom and everyone was trying to promote their own favourite “one stop shop” for all your Internet needs.  

在过去的四分之一个世纪里，这一层也发生了相当深刻的变化，跟踪技术能力的提高和消费者需求的增长。 1990 年代末，互联网正处于门户网站狂热的风口浪尖，Look Smart 是互联网热潮中的宠儿，每个人都在努力推广自己最喜欢的“一站式商店”，以满足您的所有互联网需求。

By 1998 the AltaVista search engine had made its debut, and these content collation portals were already becoming passe. This change, from compiling directories and lists to active search, completely changed the Internet. These days we simply assume that we can type any query we like into a search engine and the search machinery will deliver a set of pointers to relevant documents. And every time this occurs our expectations about the quality and utility of search engines are reinforced. Content is also changing as a result, as users no longer remain on a single site and navigate across the pages that are found at that site. Instead, users are driving search engines, and pulling the relevant pages without reference to any other material. But it’s not stopped there. Search engines are morphing into “instant answer machines” where instead of providing a set of pointers to sources where there is a high level of correlation between the source and the question, the search engine attempts to extract material from the source and show what it believes is the answer to the implicit question in the search term. Even this is just a waypoint in a longer journey, and today we are seeing AI chat bots appearing, where the underlying data set that has been indexed by the search machinery is now being used as a corpus of data to drive an AI chat engine. The interaction is based a natural language model.  

到 1998 年，AltaVista 搜索引擎首次亮相，这些内容整理门户已经过时了。这种从编制目录和列表到主动搜索的变化彻底改变了互联网。如今，我们简单地假设我们可以在搜索引擎中输入任何我们喜欢的查询，搜索机器将提供一组指向相关文档的指针。每次这种情况发生时，我们对搜索引擎的质量和实用性的期望都会增强。结果，内容也在发生变化，因为用户不再停留在单个站点上并在该站点上找到的页面之间进行导航。相反，用户正在驱动搜索引擎，并在不参考任何其他材料的情况下提取相关页面。但事情并没有就此停止。搜索引擎正在演变成“即时答题机”，搜索引擎不再提供一组指向来源和问题之间存在高度相关性的来源的指针，而是尝试从来源中提取材料并显示它所相信的内容是搜索词中隐含问题的答案。即使这只是漫长旅程中的一个路点，今天我们看到人工智能聊天机器人的出现，其中由搜索机器索引的底层数据集现在被用作数据语料库来驱动人工智能聊天引擎。交互基于自然语言模型。

If you thought of the Internet as an information resource, then the use of AI in this manner is a disturbing step. In this AI model the responding system generates plausible, but very definitely not necessarily factual, natural language responses to the implicit question in the query. It’s challenging to see this path from indexing data sources and matching query terms to the terms used primary sources to one of a natural language generator that produces textual responses that is not grounded in facts nor necessarily derived from primary sources as being progress! Despite such misgivings about the deliberate abasement of the quality of the Internet as an information resource, this shift does fit into a larger picture of the Internet’s transformation to mass entertainment vehicle, which is much of the driving force in today’s content world.  

如果你将互联网视为一种信息资源，那么以这种方式使用人工智能是令人不安的一步。在这个人工智能模型中，响应系统对查询中的隐含问题生成看似合理但不一定是事实的自然语言响应。从对数据源建立索引、将查询术语与主要来源所使用的术语进行匹配，到生成既不基于事实又不一定源自主要来源的文本响应的自然语言生成器之一，将这一路径视为进步是具有挑战性的！尽管人们对故意降低互联网作为信息资源的质量存在这样的疑虑，但这种转变确实符合互联网向大众娱乐工具转型的大局，而大众娱乐工具是当今内容世界的主要推动力。

A related area of profound change has been the rise of social media. The television, radio, film and print industries had evolved to use content mediators, compilers and editors to curate their content, and the widespread deployment of highly capable user devices allowed end users to directly perform content production without the need to engage with mediators or producers. This has transformed many societies, and the social media platforms, including YouTube, Flickr, Facebook, Instagram and Tiktok, have been rocketed into societal prominence, prompting major debates about the role of these platforms and levels of societal influence that such platforms can generate.  

一个相关的深刻变革领域是社交媒体的兴起。电视、广播、电影和印刷行业已经发展到使用内容中介、编译器和编辑来管理其内容，并且高性能用户设备的广泛部署允许最终用户直接进行内容制作，而无需与中介或制作人互动。这改变了许多社会，包括 YouTube、Flickr、Facebook、Instagram 和 Tiktok 在内的社交媒体平台已迅速获得社会关注，引发了关于这些平台的作用以及这些平台可以产生的社会影响力水平的重大辩论。

Underlying these changes is another significant development, namely the change in the content economy. In 1998 content providers and ISPs were eyeing each other off in a fight for user revenue. Content providers were unable to make pay per view and other forms of direct financial relationship with users work in their favour and were arguing that ISPs should fund content. After all, they argued, the only reason why users paid for Internet access was because of the perceived value of the content that they found on the Internet. ISPs, on the other hand, took up the stance that content providers were enjoying a free ride across the ISP-funded infrastructure, and content providers should contribute to network costs. The model that has gained ascendency as a result of this unresolved tension is that of advertised-funded content services, and this model has been capable of sustaining a vastly richer, larger, and more compelling content environment.  

这些变化的背后是另一个重大发展，即内容经济的变化。 1998 年，内容提供商和 ISP 为争夺用户收入而互相虎视眈眈。内容提供商无法使按次付费以及与用户建立其他形式的直接财务关系对他们有利，因此认为 ISP 应该为内容提供资金。他们认为，毕竟，用户付费访问互联网的唯一原因是他们对在互联网上找到的内容的感知价值。另一方面，互联网服务提供商采取的立场是，内容提供商在互联网服务提供商资助的基础设施上享受免费乘车服务，内容提供商应该承担网络成本。由于这种悬而未决的紧张局势而获得优势的模式是广告资助的内容服务模式，这种模式能够维持一个更丰富、更大、更引人注目的内容环境。

However, this comes at a price, and in this case the price lies in the motivations of the platforms that perform ad delivery. The critical objective now is to engage the user for longer periods, so that more ads can be presented, and more information about the user’s profile can be gleaned. Merely informing a user is largely a transactional interaction, whereas entertaining a user can be far more lucrative in terms of generating advertising revenue because of the longer attention span. This has been highly successful for some content players, particular the current giants of streaming content, and its therefore unsurprising that the largest entities in the content world, such as Alphabet, Microsoft and Amazon and Apple are far more valuable in terms of market capitalization than their counterparts in the carriage world. We are now seeing the next round of the friction between content and carriage where the access network operators are arguing that the content players should contribute to the costs of access carriage.  

然而，这是有代价的，在这种情况下，代价在于执行广告投放的平台的动机。现在的关键目标是让用户参与更长时间，以便可以展示更多广告，并收集更多有关用户个人资料的信息。仅仅通知用户在很大程度上是一种交易交互，而娱乐用户由于注意力持续时间更长，在产生广告收入方面可能更有利可图。这对一些内容玩家来说非常成功，特别是当前的流媒体内容巨头，因此毫不奇怪，内容世界中最大的实体，如 Alphabet、微软、亚马逊和苹果，在市值方面远比其他内容公司更有价值。他们在运输界的同行。我们现在看到内容和运输之间的下一轮摩擦，接入网络运营商认为内容运营商应该承担接入运输成本。

The Domain Name System (DNS) also merits a mention in this section. From one perspective little has changed in this space, and the DNS name resolution protocol hasn’t changed to any appreciable extent. In some sense that’s true, but at the same time there have been some significant changes.  

本节还值得一提的是域名系统 (DNS)。从一个角度来看，这一领域几乎没有发生任何变化，DNS 名称解析协议也没有发生任何明显的变化。从某种意义上说这是事实，但同时也发生了一些重大变化。

The first of these changes is in the adoption of DNSSEC, a framework that allows DNS clients to validate the answers that they receive from the DNS. The DNS has always been a point of security vulnerability on the Internet in that it has always been prone to various forms of attack where false answers are substituted in place of the genuine answer. DNSSEC provides a digital signature record to each normal record, and also implements an interlocked chain of signatures to link to the key associated with the root zone. A client may request the signature record to be provided with the normal response, and then make further requests to construct the validation chain all the way to the root zone. Successful validation assures a client that the data provided in the original response is authentic and current. The root zone of the DNS was first signed in 2010, but adoption of DNSSEC has been slow. While the addition of such a validation mechanism is undoubtedly a step forward in protecting users against various forms of name-based interference, the cost is increased fragility of the DNS and increased resolution times. One underlying issue is that the addition of digital signatures to a DNS response is highly likely to push the DNS into sending large responses, and large responses over a UDP-based transport is prone to fragmentation-based unreliability, and the switch to use TCP also takes time. What this has implied is that the path to adoption of DNSSEC has been slow, despite the obvious protections it can provide regarding potential tampering with the DNS.  

第一个变化是采用 DNSSEC，这是一个允许 DNS 客户端验证从 DNS 收到的答案的框架。 DNS 一直是互联网上的一个安全漏洞点，因为它总是容易受到各种形式的攻击，其中错误答案会取代真实答案。 DNSSEC 为每个普通记录提供数字签名记录，并且还实现了一个互锁的签名链以链接到与根区域关联的密钥。客户端可以请求提供正常响应的签名记录，然后发出进一步的请求以构建一直到根区域的验证链。成功的验证可向客户保证原始响应中提供的数据是真实且最新的。 DNS 的根区域于 2010 年首次签署，但 DNSSEC 的采用进展缓慢。虽然增加这样的验证机制无疑是保护用户免受各种形式的基于名称的干扰的一个进步，但代价是增加了 DNS 的脆弱性并增加了解析时间。一个根本问题是，在 DNS 响应中添加数字签名很可能会促使 DNS 发送大型响应，而基于 UDP 传输的大型响应很容易出现基于分段的不可靠性，并且切换到使用 TCP需要时间。这意味着，尽管 DNSSEC 可以针对潜在的 DNS 篡改提供明显的保护，但采用 DNSSEC 的进程一直很缓慢。

The second major theme of change in the DNS concerns the larger issue of pervasive monitoring in the DNS, highlighted by the Snowden revelations of 2013. Most Internet transactions start with a call to the DNS, and the meta-data contained in DNS queries and responses provides a rich real-time profile of user activity, both in general and potentially on a user-by-user basis. This has prompted a concerted effort to improve the privacy aspects of the DNS as a protocol. One approach has been to take the existing use of DNS across a TCP session and add Transport Layer Security (TLS) to the TCP session, so the contents of the interaction between the client and the DNS server are impervious to third party inspection or manipulation. This can be taken a step further with DNS over HTTPS/2 where the DNS payload has a lightweight HTTP wrapper in addition to TLS. This allows DNS traffic to be melded in with all other HTTP traffic as a further step of obscuring DNS transactions. More recently we’ve seen DNS over QUIC, using QUIC’s faster session start times and fast open capabilities to improve the performance of the arrangement and DNS over HTTPS/3 which combines QUIC with HTTP object semantics. The primary focus of this work has been the part of the DNS where the client’s stub resolver interacts with a recursive resolver, as this scenario identifies the client. The useful property of this part of the DNS is that the same client / server setup is used repeatedly, so either a long-held secure transport session, or a fast-reopen session can amortise the high cost of set up of a reliable secure session over many subsequent queries, making the overall cost of such secure transport arrangement more palatable.  

DNS 变化的第二个主要主题涉及 DNS 中普遍监控的更大问题，2013 年的斯诺登泄密事件凸显了这一点。大多数互联网交易都是从调用 DNS 开始的，以及 DNS 查询和响应中包含的元数据提供丰富的用户活动实时概况，包括一般情况和潜在的逐个用户的情况。这促使人们共同努力改善 DNS 作为协议的隐私方面。一种方法是在 TCP 会话中采用 DNS 的现有使用，并向 TCP 会话添加传输层安全性 (TLS)，这样客户端和 DNS 服务器之间的交互内容就不会受到第三方检查或操纵。这可以通过 HTTPS/2 上的 DNS 更进一步，其中 DNS 有效负载除了 TLS 之外还有一个轻量级 HTTP 包装器。这使得 DNS 流量能够与所有其他 HTTP 流量融合在一起，作为隐藏 DNS 事务的进一步步骤。最近，我们看到了 DNS over QUIC，使用 QUIC 更快的会话启动时间和快速打开功能来提高系统性能，以及 DNS over HTTPS/3，它将 QUIC 与 HTTP 对象语义相结合。这项工作的主要焦点是客户端的存根解析器与递归解析器交互的 DNS 部分，因为此场景识别客户端。 DNS 这部分的有用属性是重复使用相同的客户端/服务器设置，因此长期保持的安全传输会话或快速重新打开的会话可以分摊建立可靠安全会话的高成本经过许多后续查询，使得这种安全传输安排的总体成本更容易接受。

Such measures still have some security issues, as the recursive resolver is privy to both the client’s identity and the DNS queries that they are making. Recent work has been undertaken on an “oblivious” model of DNS operation, where the recursive resolver function is split in two and two layers of encryption of used. The client talks to the first party, a DNS relay over an encrypted session, and passes it a query which has been encrypted using the public key of the second party, the recursive resolver. The relay resends the encrypted DNS query to the recursive resolver to resolve. The first party knows the identity of the client, but not the DNS query that is being made. The second party knows the DNS query, but not the identity of the client.  

此类措施仍然存在一些安全问题，因为递归解析器了解客户端的身份及其正在进行的 DNS 查询。最近的工作涉及 DNS 操作的“遗忘”模型，其中递归解析器功能分为两层和两层加密。客户端与第一方（通过加密会话的 DNS 中继）进行对话，并向其传递已使用第二方（递归解析器）的公钥加密的查询。中继将加密的 DNS 查询重新发送到递归解析器进行解析。第一方知道客户端的身份，但不知道正在进行的 DNS 查询。第二方知道 DNS 查询，但不知道客户端的身份。

This work on DNS privacy has extended into the scenarios of the recursive resolver taking with authoritative name servers, although it’s unclear as to the extent of the security benefits (as the end user is not identified directly in such queries), nor is session reuse as feasible in this scenario.  

这项有关 DNS 隐私的工作已扩展到递归解析器与权威名称服务器一起使用的场景，尽管尚不清楚安全优势的程度（因为在此类查询中没有直接识别最终用户），会话重用也不是这样的。在这种情况下可行。

In many ways applications and services have been the high frontier of innovation in the Internet in this period. An entire revolution in open interconnection of content elements has taken place and content is now a very malleable concept. It’s no longer the case of “my computer, my applications, my workspace” or “your server, your content” but an emerging model where not only the workspace for each user is held in the network, but where the applications and services themselves are part of the network, and all are accessed through a generic mechanism based around permutations of the HTTPS access model. This is the world of so-called “cloud services”. The world of cloud services takes advantage of abundance in computation, storage, and communications resources and rather than a network facilitating users to connect to service delivery points, the cloud model inverts the model and attempts to bring replicant copies of content and services closer to the user. If distance equates to cost and performance in the networking world, then the cloud model dramatically shortens the distance between consumer and content, with obvious implications in terms of cost and performance reductions. The clouded Internet is capable of achieving extremely challenging performance and cost objectives by changing the provisioning model of the content and service from “just in time” on-demand service to “just in case” pre-provisioning of local caches so that the local cache is ready if the service is accessed by a local client.  

在许多方面，应用程序和服务一直是这一时期互联网创新的前沿。内容元素的开放互连已经发生了一场彻底的革命，内容现在是一个非常可塑的概念。它不再是“我的计算机、我的应用程序、我的工作空间”或“你的服务器、你的内容”，而是一种新兴的模型，其中不仅每个用户的工作空间都保存在网络中，而且应用程序和服务本身也保存在网络中。网络的一部分，并且所有内容都通过基于 HTTPS 访问模型排列的通用机制进行访问。这就是所谓的“云服务”的世界。云服务世界利用了丰富的计算、存储和通信资源，而不是通过网络方便用户连接到服务交付点，云模型颠倒了模型，并试图使内容和服务的复制副本更接近于现实。用户。如果距离等同于网络世界中的成本和性能，那么云模型将极大地缩短消费者和内容之间的距离，在成本和性能降低方面具有明显的影响。通过将内容和服务的供应模式从“及时”按需服务转变为“以防万一”预先供应本地缓存，云互联网能够实现极具挑战性的性能和成本目标。如果本地客户端访问该服务，则已准备就绪。

### Cyber Hostility 网络敌意

We still are under relentless attack at all levels. We are beset by data leaks, surveillance, profiling, disruption, and extortion.  

我们仍然受到各个层面的无情攻击。我们受到数据泄露、监视、分析、破坏和勒索的困扰。

Attacks are now commonplace. Many of them are brutally simple, relying on a tragically large pool of potential zombie devices that are readily subverted and co-opted to assist in attacks. The attacks are often simple, such as UDP reflection attacks where a single UDP query generates a large response. The source address of the query is forged to be the address of the intended attack victim, and not much more needs to be done. A small query stream can result in a massive attack. UDP protocols such as SNMP, the Network Time Protocol (NTP), the DNS, and memcached have been used in the past and doubtless will be used again.  

攻击现在已是司空见惯。其中许多都非常简单，依赖于大量潜在的僵尸设备，这些设备很容易被破坏并被用来协助攻击。这些攻击通常很简单，例如 UDP 反射攻击，其中单个 UDP 查询会生成大量响应。查询的源地址被伪造为预期攻击受害者的地址，不需要做更多的事情。一个小的查询流可能会导致大规模的攻击。 SNMP、网络时间协议 (NTP)、DNS 和 memcached 等 UDP 协议过去已被使用，并且毫无疑问将再次被使用。

Why can’t we fix this problem? We’ve been trying for decades, and we just can’t seem to get ahead of the attacks. Advice to network operators to prevent the leakage of packets with forged source addresses was published nearly two decades ago, in 2000. Yet massive UDP based attacks with forged source addresses still persist today. Aged computer systems with known vulnerabilities continue to be connected to the Internet and are readily transformed into attack bots.  

为什么我们不能解决这个问题？我们几十年来一直在努力，但似乎无法在攻击面前脱颖而出。近二十年前（即 2000 年）向网络运营商发布了防止伪造源地址数据包泄漏的建议。然而，基于伪造源地址的大规模 UDP 攻击至今仍然存在。具有已知漏洞的老化计算机系统继续连接到互联网，并且很容易转变为攻击机器人。

The picture of attacks is also becoming more ominous. Although we previously attributed these hostile attacks to “hackers,” we quickly realised that a significant component of them had criminal motivations. The progression from criminal actors to state-based actors is also entirely predictable, and we are seeing an escalation of this cyber warfare arena with the investment in various forms of vulnerability exploitation that are considered desirable national capabilities.  

袭击的情况也变得更加不祥。尽管我们之前将这些恶意攻击归咎于“黑客”，但我们很快意识到其中很大一部分具有犯罪动机。从犯罪行为者到国家行为者的进展也是完全可以预测的，而且我们看到这个网络战领域不断升级，对各种形式的漏洞利用的投资被认为是理想的国家能力。

It appears that a major problem here is that collectively we are unwilling to make any substantial investment in effective defence or deterrence. The systems that we use on the Internet are overly trusting to the point of irrational credulity. For example, the public key certification system used to secure web-based transactions is repeatedly demonstrated to be entirety untrustworthy, yet that’s all we trust. Personal data is continually breached and leaked, yet all we seem to want to do is increase the number and complexity of regulations rather than actually use better tools that would effectively protect users.  

看来这里的一个主要问题是，我们集体不愿意在有效防御或威慑方面进行任何实质性投资。我们在互联网上使用的系统过度信任，达到了非理性轻信的程度。例如，用于保护基于网络的交易的公钥认证系统被多次证明是完全不可信的，但这就是我们所信任的。个人数据不断被破坏和泄露，但我们似乎想做的只是增加法规的数量和复杂性，而不是实际使用更好的工具来有效保护用户。

The larger picture of hostile attack is not getting any better. Indeed, it’s getting very much worse. If any enterprise has a business need to maintain a service that is always available for use, then any form of in-house provisioning is just not enough to withstand attack. These days only a handful of platforms can offer resilient services, and even then, it’s unclear whether they could withstand the most extreme of attacks.  

敌对攻击的大局并没有好转。事实上，情况变得更糟了。如果任何企业都有维护始终可用的服务的业务需求，那么任何形式的内部配置都不足以抵御攻击。如今，只有少数平台可以提供弹性服务，即使如此，也不清楚它们是否能够承受最极端的攻击。

A constant background level of scanning and probing goes on in the network, and any form of visible vulnerability is ruthlessly exploited. One could describe today’s Internet as a toxic wasteland, punctuated with the occasional heavily defended citadel. Those who can afford to locate their services within these citadels enjoy some level of respite from this constant profile of hostile attack, while all others are forced to try to conceal themselves from the worst of this toxic environment, while at the same time aware that they will be completely overwhelmed by any large-scale attack. It is a sobering thought that about one-half of the world’s population are now part of this digital environment. A more sobering thought is that many of today’s control systems, such as power generation and distribution, water distribution, and road-traffic-control systems are exposed to the Internet.  

网络中持续进行后台级别的扫描和探测，任何形式的可见漏洞都会被无情地利用。人们可以将今天的互联网描述为一片有毒的荒地，偶尔会有戒备森严的城堡。那些有能力在这些城堡内提供服务的人可以从这种持续不断的敌对攻击中得到一定程度的喘息，而所有其他人则被迫试图隐藏自己，免受这种有毒环境中最糟糕的影响，同时意识到他们任何大规模的攻击都会被彻底压垮。世界上大约一半的人口现在是这个数字环境的一部分，这是一个发人深省的想法。一个更发人深省的想法是，当今的许多控制系统，例如发电和配电、供水和道路交通控制系统都暴露在互联网上。

What makes this scenario even more depressing is the portent of the so-called Internet of Things (IoT). In those circles where Internet prognostications abound and policy makers flock to hear grand visions of the future, we often hear about the boundless future represented by this Internet of Things. This phrase encompasses some decades of the computing industry’s transition from computers as esoteric pieces of engineering affordable only by nations to mainframes, desktops, laptops, handheld devices, and now wrist computers.  

使这种情况变得更加令人沮丧的是所谓的物联网（IoT）的预兆。在互联网预言比比皆是、政策制定者蜂拥而至聆听未来宏伟愿景的圈子里，我们经常听到物联网所代表的无限未来。这句话涵盖了计算行业几十年来的转变，从计算机作为只有国家才能负担得起的深奥工程，到大型机、台式机、笔记本电脑、手持设备，以及现在的腕式计算机。

Where next? In the vision of the IoT we are going to expand the Internet beyond people and press on using billions of these chattering devices in every aspect of our world. What do we know about the “things” that are already connected to the Internet? Some of them are not very good. In fact, some of them are just plain stupid. And this stupidity is toxic, in that their sometime-inadequate models of operation and security affect others in potentially malicious ways.  

接下来去哪里？在物联网的愿景中，我们将把互联网扩展到人类之外，并努力在世界的各个方面使用数十亿个这样的聊天设备。对于已经连接到互联网的“事物”，我们了解多少？其中一些不是很好。事实上，他们中的一些人简直就是愚蠢的。这种愚蠢是有毒的，因为它们有时不充分的操作和安全模型会以潜在的恶意方式影响其他人。

If such devices were constantly inspected and managed, we might see evidence of aberrant behaviour and correct it. But these devices are unmanaged and all but invisible. Examples include the controller for a web camera, the so-called “smart” thing in a smart television, or the controls for anything from a washing machine to a goods locomotive. Nobody is looking after these devices. When we think of an IoT we think of a world of weather stations, webcams, “smart” cars, personal fitness monitors, and similar things.  

如果不断检查和管理此类设备，我们可能会发现异常行为的证据并予以纠正。但这些设备不受管理且几乎不可见。例子包括网络摄像头的控制器、智能电视中所谓的“智能”设备，或者从洗衣机到货运机车的任何东西的控制器。没有人照顾这些设备。当我们想到物联网时，我们会想到一个由气象站、网络摄像头、“智能”汽车、个人健身监视器和类似事物组成的世界。

But what we tend to forget is that all of these devices are built on layers of other people’s software that is assembled into a product at the cheapest possible price point. It may be disconcerting to realise that the web camera you just installed has a security model that can be summarised with the phrase: “no security at all,” and it’s actually offering a view of your house to the entire Internet. It may be slightly more disconcerting to realise that your electronic wallet is on a device that is using a massive compilation of open-source software of largely unknown origin, with a security model that is not completely understood, but appears to be susceptible to be coerced into being a “yes, take all you want” device. It would be nice to think that we’ve stopped making mistakes in code, and from now on our software in our things will be perfect. But that’s hopelessly idealistic. It’s just not going to happen. Software will not be perfect. It will continue to have vulnerabilities.  

但我们往往忘记的是，所有这些设备都是建立在其他人的软件层之上的，这些软件以尽可能便宜的价格组装成产品。您可能会感到不安，因为您刚刚安装的网络摄像头具有可以用一句话来概括的安全模型：“根本没有安全性”，而它实际上是向整个互联网提供您房屋的视图。意识到您的电子钱包所在的设备正在使用大量来源不明的开源软件，其安全模型尚未完全理解，但似乎很容易受到强制，这可能会稍微令人不安成为一个“是的，想要什么就拿什么”的设备。如果我们已经不再在代码中犯错误，并且从现在开始我们的软件将变得完美，那就太好了。但这是无可救药的理想主义。这不会发生。软件不会是完美的。它将继续存在漏洞。

It would be nice to think that this Internet of Things is shaping up as a market where quality matters, and consumers will select a more expensive product even though its functional behaviour is identical to a cheaper product that has not been robustly tested for basic security flaws. But that too is hopelessly naive.  

很高兴认为物联网正在形成一个质量至关重要的市场，消费者会选择更昂贵的产品，即使其功能行为与尚未经过基本安全缺陷严格测试的更便宜产品相同。但这也太天真了。

The Internet of Things will continue to be a marketplace where the compromises between price and quality will continue to push us on to the side of cheap rather than secure. What’s going to stop us from further polluting our environment with a huge and diverse collection of programmed unmanaged devices with inbuilt vulnerabilities that will be all too readily exploited? What can we do to make this world of these stupid cheap toxic things less stupid and less toxic? So far, we have not found workable answers to this question.  

物联网将继续成为一个市场，价格和质量之间的妥协将继续将我们推向廉价而非安全的一边。什么才能阻止我们进一步污染我们的环境，使用大量多样化的已编程的非托管设备，这些设备具有很容易被利用的内置漏洞？我们能做些什么来让这个充斥着愚蠢廉价有毒物质的世界变得不那么愚蠢、毒性更少呢？到目前为止，我们还没有找到这个问题的可行答案。

Our ability to effectively defend the network and its connected hosts continues to be, on the whole, ineffectual. Anyone who still has trust in the integrity of the systems that make up the digital world is just hopelessly naive. This is a toxic and hostile space, and we still have no idea how we can shift this to a different state that can resist such erosive and insidious attacks. But somehow, we are evidently not deterred by all this. Somehow each of us have found a way to make the Internet work for each of us.  

总体而言，我们有效防御网络及其连接主机的能力仍然无效。任何仍然相信构成数字世界的系统完整性的人都是无可救药的天真。这是一个有毒且充满敌意的空间，我们仍然不知道如何将其转变为可以抵抗这种侵蚀性和阴险攻击的不同状态。但不知何故，我们显然并没有被这一切吓倒。不知何故，我们每个人都找到了一种让互联网为我们每个人服务的方法。

### The Business of the Internet  

互联网业务

As much as the application environment of the Internet has been on a wild ride over the past 25 years, the business environment has also had its tickets on the same roller coaster ride, and the list of business winners and losers include some of the historical giants of the telephone world as well as the Internet-bred new wave of entrants.  

过去25年来，互联网的应用环境经历了疯狂的旅程，商业环境也经历了同样的过山车，商业赢家和输家的名单中包括一些历史巨头。电话世界以及互联网孕育的新进入者浪潮。

In 1998, despite the growing momentum of public awareness, the Internet was still largely a curiosity. It was an environment inhabited by geeks, game players and academics, whose rites of initiation were quite arcane. As a part of the data networking sector, the Internet was just one further activity among many, and the level of attention from the mainstream telco sector was still relatively small. Most Internet users were customers of independent ISPs and the business relationship between the ISP sector and the telco was tense and acrimonious. The ISPs were seen as opportunistic leeches on the telco industry; they ordered large banks of phone lines, but never made any calls; their customers did not hang up after 3 minutes, but kept their calls open for hours or even days at a time, and they kept on ordering ever larger inventories of transmission capacity, yet had business plans that made scribblings on the back of an envelope look professional by comparison. The telco was unwilling to make large long term capital investments in additional communications infrastructure to pander to the extravagant demands of a wildcat set of internet speculators and their fellow travellers. The telco, on the other hand was slow, expensive, inconsistent, ill-informed and hostile to the ISP business. The telco wanted financial settlements and bit level accounting while the ISP industry appeared to manage quite well with a far simpler system of peering and tiering that avoided putting a value on individual packets or flows.  

1998 年，尽管公众意识不断增强，但互联网在很大程度上仍然是一种好奇。这是一个充满极客、游戏玩家和学者的环境，他们的入会仪式相当神秘。作为数据网络领域的一部分，互联网只是众多活动中的一个，主流电信行业的关注度还相对较小。大多数互联网用户都是独立 ISP 的客户，ISP 部门与电信公司之间的业务关系紧张且激烈。互联网服务提供商被视为电信行业的机会主义吸血者；他们订购了大量电话线，但从未拨打过任何电话；他们的客户在三分钟后并没有挂断电话，而是一次连续几个小时甚至几天保持通话，他们不断订购更大的传输容量库存，但他们的商业计划却像是信封背面的潦草字迹。比较专业。该电信公司不愿意在额外的通信基础设施上进行大量的长期资本投资，以迎合一群野猫式的互联网投机者及其同行的奢侈需求。另一方面，电信公司速度慢、成本高、不稳定、消息灵通并且对 ISP 业务怀有敌意。电信公司需要财务结算和位级会计，而 ISP 行业似乎通过更简单的对等和分层系统管理得很好，避免了对单个数据包或流进行评估。

This was never a relationship that was going to last, and it resolved itself in ways that in retrospect were quite predictable. From the telco perspective it quickly became apparent that the only reason why the telco was being pushed to install additional network capacity at ever increasing rates was the ISP sector. From the ISP perspective the only way to grow at a rate that matched customer demand was to become one’s own carrier and to take over infrastructure investment. And, in various ways, both outcomes occurred. Telcos bought up ISPs, and ISPs became infrastructure carriers.  

这从来都不是一种能够持续下去的关系，而且它的解决方式在回想起来是完全可以预见的。从电信公司的角度来看，很快就发现电信公司被迫以不断增加的速度安装额外网络容量的唯一原因是 ISP 部门。从 ISP 的角度来看，以符合客户需求的速度增长的唯一方法是成为自己的运营商并接管基础设施投资。而且，这两种结果都以不同的方式发生了。电信公司收购了 ISP，ISP 成为基础设施运营商。

All this activity generated considerable investor interest, and the rapid value escalation of the ISP industry and then the entire Internet sector generated the levels of wild-eyed optimism that are only associated with an exceptional boom. By 2000 almost anything associated with the Internet, whether it was a simple portal, a new browser development, a search engine, or an ISP, attracted investor attention, and the valuations of internet startups achieved dizzying heights. Of course, one of the basic lessons of economic history is that every boom has an ensuing bust, and in 2001 the Internet collapse happened. The bust was as inevitable and as brutal as the preceding boom was euphoric. But, like the railway boom and bust of the 1840’s, once the wreckage was cleared away, what remained was a viable, and indeed a valuable, industry.  

所有这些活动都引起了相当大的投资者兴趣，ISP 行业乃至整个互联网行业的价值迅速提升，引发了狂热的乐观情绪，这种乐观情绪只有与异常繁荣相关。到了 2000 年，几乎所有与互联网相关的东西，无论是简单的门户、新的浏览器开发、搜索引擎还是 ISP，都吸引了投资者的注意力，互联网初创公司的估值达到了令人目眩的高度。当然，经济史的基本教训之一是，每一次繁荣都会随之而来的萧条，2001年发生了互联网崩溃。萧条是不可避免的，也是残酷的，就像之前的繁荣是令人欣喜的一样。但是，就像 1840 年代铁路的繁荣和萧条一样，一旦残骸被清除，剩下的就是一个可行的、实际上是一个有价值的行业。

By 2003 the era of the independent retail ISP was effectively over. But it reshaped itself dramatically with the introduction of mobile services. It was the old telco sector that had secured spectrum allocations in the bidding ways for the early 2000’s and while they had thought that mobile voice would be the reason why these investments would make sense, it was mobile internet services that proved to be the lasting service model. In this period the Internet was the amalgam of the largest of the original ISP, the transformed cable television operators and the mobile providers. Each national regime was populated with some 3 to 5 major service providers and the business started to stabilise around this model.  

到 2003 年，独立零售 ISP 的时代实际上已经结束。但随着移动服务的推出，它极大地重塑了自己。老电信部门在 2000 年代初期通过招标方式获得了频谱分配，虽然他们认为移动语音是这些投资有意义的原因，但事实证明移动互联网服务是持久的服务模型。在此期间，互联网是最大的原始 ISP、转型后的有线电视运营商和移动提供商的混合体。每个国家政权都有大约 3 到 5 个主要服务提供商，并且围绕这种模式业务开始稳定下来。

Into this world came the content world of the Internet, using cloud-based models of service delivery to circumvent communications bottlenecks in the long-haul transit sector. They embarked on service models which included advertiser-funded models of content generation and delivery and direct subscription models, and the result has been so effective that the value of this sector is far greater than the traditional ISP and carriage sector. The content world is now the major funder of subsea cable systems, and the carriage world has been very reluctantly pushed into an undistinguished commodity role as a result.  

互联网的内容世界进入了这个世界，它使用基于云的服务交付模型来规避长途运输领域的通信瓶颈。他们开创了包括广告商资助的内容生成和交付模式以及直接订阅模式在内的服务模式，其结果非常有效，以至于该行业的价值远远大于传统的ISP和运输行业。内容世界现在是海底电缆系统的主要资助者，而运输世界因此被非常不情愿地推入了一个不起眼的商品角色。

This is reflective of a broader process of technology permeation. The telephone world used the network as the major focus of technology and investment. The edge devices, telephone handsets, were simple cheap devices, whereas network switches and transmission elements were built to exacting and expensive standards. As we attached computers to the edges of the network, these devices were able to tolerate a broader spectrum of network behaviours and had a lower base level expectation of behaviour. Consequently, value has moved out from the core of the network to its edges.  

这反映了更广泛的技术渗透过程。电话世界将网络作为技术和投资的主要焦点。边缘设备、电话听筒是简单廉价的设备，而网络交换机和传输元件是按照严格且昂贵的标准构建的。当我们将计算机连接到网络边缘时，这些设备能够容忍更广泛的网络行为，并且对行为的基本水平期望较低。因此，价值已经从网络的核心转移到边缘。

But this process has also been reflected within these edge devices. We started with a model of a highly capable and complicated operating system platform, and relatively simple applications that made use of platform services. Some 25 years ago the release of Windows 98 was a big thing, and rightly so. As these edge devices become more capable, have higher processing capability, and more local storage applications have elected to take on more of the responsibility in terms of the user’s experience. In doing so they are no longer reliant on the release schedules of the platform provider, no longer as concerned about the level of control being exercised by this platform provider and gaining an essential level of self-control. Modern browsers (well Chrome, and a few far smaller follow travellers) are far more complex than most operating systems, and they continue to subsume functions and roles previously carried out by the platform. With DNS over HTTPS the task of DNS name resolution can be transformed to an application function, rather than a common platform function. With QUIC, the transport protocol itself has been subsumed into the application space.  

但这个过程也反映在这些边缘设备中。我们从一个高性能且复杂的操作系统平台模型以及使用平台服务的相对简单的应用程序开始。大约 25 年前，Windows 98 的发布是一件大事，这是理所应当的。随着这些边缘设备变得更加强大，具有更高的处理能力，更多的本地存储应用程序选择在用户体验方面承担更多的责任。这样做时，他们不再依赖平台提供商的发布时间表，不再关心该平台提供商所行使的控制水平并获得基本的自我控制水平。现代浏览器（以及 Chrome 和一些较小的追随者）比大多数操作系统复杂得多，并且它们继续包含该平台以前执行的功能和角色。通过 HTTPS 上的 DNS，DNS 名称解析任务可以转变为应用程序功能，而不是通用平台功能。通过 QUIC，传输协议本身已被纳入应用程序空间。

Not only have we seen the commoditisation of the network over the past twenty-five years, we’ve seen similar commoditisation pressures on the end device platforms and on the operating systems used on these devices. Even the browser space has been commoditised. The brunt of competitive differentiation in this industry has been pushed up the protocol stack into the content and service economy, and there is the distinct feeling that even in that space competitive differentiation perhaps a misnomer, and what we have is a synthetic form of competition between a select small group of digital service delivery behemoths that in any other time and context would probably be called a cartel.  

在过去的二十五年里，我们不仅看到了网络的商品化，而且还看到了终端设备平台和这些设备上使用的操作系统面临着类似的商品化压力。甚至浏览器空间也已经商品化。这个行业中竞争差异化的冲击已经被推到了协议栈的内容和服务经济中，而且有一种明显的感觉，即使在这个领域，竞争差异化也可能是一个用词不当，而我们所拥有的是一种综合形式的竞争一小群数字服务交付巨头在任何其他时间和环境下都可能被称为卡特尔。

### What Now? 现在怎么办？

It’s been a revolutionary quarter-century for us all, and the Internet has directly or indirectly touched the lives of almost every person on this planet. Current estimates put the number of regular Internet users at one half of the world’s population.  

对于我们所有人来说，这是一个革命性的四分之一世纪，互联网直接或间接地影响了这个星球上几乎每个人的生活。目前估计，经常使用互联网的用户数量占世界人口的一半。

Over this period some of our expectations were achieved and then surpassed with apparent ease, while others remained elusive. And some things occurred that were entirely unanticipated. At the same time very little of the Internet we have today was confidently predicted in 1998, while many of the problems we saw in 1998 remain problems today.  

在此期间，我们的一些期望得到了实现，然后又明显轻松地超越了，而另一些则仍然难以捉摸。有些事情的发生是完全出乎意料的。与此同时，我们今天所拥有的互联网几乎没有在 1998 年被自信地预测过，而我们在 1998 年看到的许多问题在今天仍然是问题。

This is a work-in-progress where the next quarter-century will probably see the same level of intensity of yet more confronting structural changes to the global communications sector. And that is a somewhat scary prospect given the collection of other challenges that are confronting us all in the coming decades. At the same time, I think it would be good to believe that the Internet’s debut in our world has completely rewritten what it means to communicate, rewritten the way in which we can share our experience and knowledge, and, hopefully, rewritten the ways in which we can improve the ways we can work together on these other existential challenges for humanity and our planet.  

这是一项正在进行的工作，在接下来的四分之一个世纪中，全球通信行业可能会看到同样强度但更具挑战性的结构性变化。考虑到未来几十年我们所有人都将面临的其他挑战，这是一个有点可怕的前景。与此同时，我认为最好相信互联网在我们世界的首次亮相已经完全改写了沟通的含义，改写了我们分享经验和知识的方式，并且希望改写了我们的沟通方式。我们可以改进我们共同努力应对人类和地球的其他生存挑战的方式。
